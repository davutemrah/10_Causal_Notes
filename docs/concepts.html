<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Concepts | Notes on Causal Models</title>
  <meta name="description" content="This is a collection of notes from open sources" />
  <meta name="generator" content="bookdown 0.35 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Concepts | Notes on Causal Models" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a collection of notes from open sources" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Concepts | Notes on Causal Models" />
  
  <meta name="twitter:description" content="This is a collection of notes from open sources" />
  

<meta name="author" content="DEA" />


<meta name="date" content="2025-08-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="potential-outcomes.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Causal Model Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Acknowledgement</a></li>
<li class="chapter" data-level="1" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i><b>1</b> Concepts</a>
<ul>
<li class="chapter" data-level="1.1" data-path="concepts.html"><a href="concepts.html#goodness-of-fit"><i class="fa fa-check"></i><b>1.1</b> Goodness of Fit</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="concepts.html"><a href="concepts.html#r-squared-r2"><i class="fa fa-check"></i><b>1.1.1</b> R-squared (<span class="math inline">\(R^2\)</span>)</a></li>
<li class="chapter" data-level="1.1.2" data-path="concepts.html"><a href="concepts.html#adjusted-r-squared"><i class="fa fa-check"></i><b>1.1.2</b> Adjusted R-squared</a></li>
<li class="chapter" data-level="1.1.3" data-path="concepts.html"><a href="concepts.html#root-mean-squared-error-rmse-mean-absolute-error-mae"><i class="fa fa-check"></i><b>1.1.3</b> Root Mean Squared Error (RMSE) / Mean Absolute Error (MAE)</a></li>
<li class="chapter" data-level="1.1.4" data-path="concepts.html"><a href="concepts.html#aic-bic-information-criteria"><i class="fa fa-check"></i><b>1.1.4</b> AIC / BIC (Information Criteria)</a></li>
<li class="chapter" data-level="1.1.5" data-path="concepts.html"><a href="concepts.html#f-statistics-and-joint-significance-tests"><i class="fa fa-check"></i><b>1.1.5</b> F-statistics and Joint Significance Tests</a></li>
<li class="chapter" data-level="1.1.6" data-path="concepts.html"><a href="concepts.html#balance-checks-causal-context"><i class="fa fa-check"></i><b>1.1.6</b> Balance Checks (Causal Context)</a></li>
<li class="chapter" data-level="1.1.7" data-path="concepts.html"><a href="concepts.html#key-distinction-prediction-vs.-causality"><i class="fa fa-check"></i><b>1.1.7</b> Key Distinction: Prediction vs. Causality</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="concepts.html"><a href="concepts.html#validation-methods"><i class="fa fa-check"></i><b>1.2</b> Validation Methods</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="concepts.html"><a href="concepts.html#internal-validity"><i class="fa fa-check"></i><b>1.2.1</b> Internal Validity</a></li>
<li class="chapter" data-level="1.2.2" data-path="concepts.html"><a href="concepts.html#external-validity"><i class="fa fa-check"></i><b>1.2.2</b> External Validity</a></li>
<li class="chapter" data-level="1.2.3" data-path="concepts.html"><a href="concepts.html#robustness-checks"><i class="fa fa-check"></i><b>1.2.3</b> Robustness Checks</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="concepts.html"><a href="concepts.html#directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>1.3</b> Directed Acyclic Graphs (DAGs)</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="concepts.html"><a href="concepts.html#confounder"><i class="fa fa-check"></i><b>1.3.1</b> Confounder</a></li>
<li class="chapter" data-level="1.3.2" data-path="concepts.html"><a href="concepts.html#collider"><i class="fa fa-check"></i><b>1.3.2</b> Collider</a></li>
<li class="chapter" data-level="1.3.3" data-path="concepts.html"><a href="concepts.html#what-to-do-and-how-to-do-it"><i class="fa fa-check"></i><b>1.3.3</b> What To Do and How To Do It</a></li>
<li class="chapter" data-level="1.3.4" data-path="concepts.html"><a href="concepts.html#example-sample-selection-and-collider-bias"><i class="fa fa-check"></i><b>1.3.4</b> Example: Sample Selection and collider bias</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="concepts.html"><a href="concepts.html#bad-controls"><i class="fa fa-check"></i><b>1.4</b> Bad Controls</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="concepts.html"><a href="concepts.html#definition"><i class="fa fa-check"></i><b>1.4.1</b> Definition</a></li>
<li class="chapter" data-level="1.4.2" data-path="concepts.html"><a href="concepts.html#why-theyre-problematic"><i class="fa fa-check"></i><b>1.4.2</b> Why They’re Problematic</a></li>
<li class="chapter" data-level="1.4.3" data-path="concepts.html"><a href="concepts.html#examples"><i class="fa fa-check"></i><b>1.4.3</b> Examples</a></li>
<li class="chapter" data-level="1.4.4" data-path="concepts.html"><a href="concepts.html#identifying-good-vs.-bad-controls"><i class="fa fa-check"></i><b>1.4.4</b> Identifying Good vs. Bad Controls</a></li>
<li class="chapter" data-level="1.4.5" data-path="concepts.html"><a href="concepts.html#best-practices"><i class="fa fa-check"></i><b>1.4.5</b> Best Practices</a></li>
<li class="chapter" data-level="1.4.6" data-path="concepts.html"><a href="concepts.html#practical-advice"><i class="fa fa-check"></i><b>1.4.6</b> Practical Advice</a></li>
<li class="chapter" data-level="1.4.7" data-path="concepts.html"><a href="concepts.html#unobserved-variable-affecting-only-the-dependent-variable"><i class="fa fa-check"></i><b>1.4.7</b> Unobserved Variable Affecting Only the Dependent Variable</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="concepts.html"><a href="concepts.html#endogeneity"><i class="fa fa-check"></i><b>1.5</b> Endogeneity</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="concepts.html"><a href="concepts.html#sources-of-endogeneity"><i class="fa fa-check"></i><b>1.5.1</b> Sources of Endogeneity</a></li>
<li class="chapter" data-level="1.5.2" data-path="concepts.html"><a href="concepts.html#consequences"><i class="fa fa-check"></i><b>1.5.2</b> Consequences</a></li>
<li class="chapter" data-level="1.5.3" data-path="concepts.html"><a href="concepts.html#solutions"><i class="fa fa-check"></i><b>1.5.3</b> Solutions</a></li>
<li class="chapter" data-level="1.5.4" data-path="concepts.html"><a href="concepts.html#summary-1"><i class="fa fa-check"></i><b>1.5.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="concepts.html"><a href="concepts.html#reduced-form-model"><i class="fa fa-check"></i><b>1.6</b> Reduced Form Model</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="concepts.html"><a href="concepts.html#characteristics-of-reduced-form-models"><i class="fa fa-check"></i><b>1.6.1</b> Characteristics of Reduced Form Models:</a></li>
<li class="chapter" data-level="1.6.2" data-path="concepts.html"><a href="concepts.html#uses-of-reduced-form-models"><i class="fa fa-check"></i><b>1.6.2</b> Uses of Reduced Form Models:</a></li>
<li class="chapter" data-level="1.6.3" data-path="concepts.html"><a href="concepts.html#example-of-a-reduced-form-model"><i class="fa fa-check"></i><b>1.6.3</b> Example of a Reduced Form Model:</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="concepts.html"><a href="concepts.html#standard-errors"><i class="fa fa-check"></i><b>1.7</b> Standard Errors</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="concepts.html"><a href="concepts.html#heteroskedasticity-consistent-standard-errors"><i class="fa fa-check"></i><b>1.7.1</b> heteroskedasticity-consistent standard errors</a></li>
<li class="chapter" data-level="1.7.2" data-path="concepts.html"><a href="concepts.html#why-use-sandwich-standard-errors"><i class="fa fa-check"></i><b>1.7.2</b> Why Use Sandwich Standard Errors?</a></li>
<li class="chapter" data-level="1.7.3" data-path="concepts.html"><a href="concepts.html#clustering-standard-errors"><i class="fa fa-check"></i><b>1.7.3</b> Clustering Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="concepts.html"><a href="concepts.html#types-of-biases-in-econometrics-statistics"><i class="fa fa-check"></i><b>1.8</b> Types of Biases in Econometrics &amp; Statistics</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="concepts.html"><a href="concepts.html#sample-selection-biases"><i class="fa fa-check"></i><b>1.8.1</b> Sample &amp; Selection Biases</a></li>
<li class="chapter" data-level="1.8.2" data-path="concepts.html"><a href="concepts.html#specification-confounding-biases"><i class="fa fa-check"></i><b>1.8.2</b> Specification &amp; Confounding Biases</a></li>
<li class="chapter" data-level="1.8.3" data-path="concepts.html"><a href="concepts.html#measurement-response-biases"><i class="fa fa-check"></i><b>1.8.3</b> Measurement &amp; Response Biases</a></li>
<li class="chapter" data-level="1.8.4" data-path="concepts.html"><a href="concepts.html#analytical-reporting-biases"><i class="fa fa-check"></i><b>1.8.4</b> Analytical &amp; Reporting Biases</a></li>
<li class="chapter" data-level="1.8.5" data-path="concepts.html"><a href="concepts.html#addressing-bias"><i class="fa fa-check"></i><b>1.8.5</b> Addressing Bias</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="concepts.html"><a href="concepts.html#causality"><i class="fa fa-check"></i><b>1.9</b> Causality</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="concepts.html"><a href="concepts.html#counterfactual-potential-outcomes-definition"><i class="fa fa-check"></i><b>1.9.1</b> Counterfactual (Potential Outcomes) Definition</a></li>
<li class="chapter" data-level="1.9.2" data-path="concepts.html"><a href="concepts.html#causal-graphs-structural-causal-models-dags"><i class="fa fa-check"></i><b>1.9.2</b> Causal Graphs (Structural Causal Models / DAGs)</a></li>
<li class="chapter" data-level="1.9.3" data-path="concepts.html"><a href="concepts.html#experimental-interventionist-definition"><i class="fa fa-check"></i><b>1.9.3</b> Experimental (Interventionist) Definition</a></li>
<li class="chapter" data-level="1.9.4" data-path="concepts.html"><a href="concepts.html#econometric-definition"><i class="fa fa-check"></i><b>1.9.4</b> Econometric Definition</a></li>
<li class="chapter" data-level="1.9.5" data-path="concepts.html"><a href="concepts.html#philosophical-humean-regularity-definition"><i class="fa fa-check"></i><b>1.9.5</b> Philosophical (Humean / Regularity) Definition</a></li>
<li class="chapter" data-level="1.9.6" data-path="concepts.html"><a href="concepts.html#granger-causality-time-series"><i class="fa fa-check"></i><b>1.9.6</b> Granger Causality (Time Series)</a></li>
<li class="chapter" data-level="1.9.7" data-path="concepts.html"><a href="concepts.html#summary-table"><i class="fa fa-check"></i><b>1.9.7</b> Summary Table</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="potential-outcomes.html"><a href="potential-outcomes.html"><i class="fa fa-check"></i><b>2</b> Potential Outcomes</a>
<ul>
<li class="chapter" data-level="2.1" data-path="potential-outcomes.html"><a href="potential-outcomes.html#key-concepts"><i class="fa fa-check"></i><b>2.1</b> Key Concepts</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="potential-outcomes.html"><a href="potential-outcomes.html#causal-effect"><i class="fa fa-check"></i><b>2.1.1</b> Causal Effect</a></li>
<li class="chapter" data-level="2.1.2" data-path="potential-outcomes.html"><a href="potential-outcomes.html#average-treatment-effect-ate"><i class="fa fa-check"></i><b>2.1.2</b> Average Treatment Effect (ATE)</a></li>
<li class="chapter" data-level="2.1.3" data-path="potential-outcomes.html"><a href="potential-outcomes.html#average-treatment-effect-on-the-treated-att"><i class="fa fa-check"></i><b>2.1.3</b> Average Treatment Effect on the Treated (ATT)</a></li>
<li class="chapter" data-level="2.1.4" data-path="potential-outcomes.html"><a href="potential-outcomes.html#the-fundamental-problem-of-causal-inference"><i class="fa fa-check"></i><b>2.1.4</b> The Fundamental Problem of Causal Inference</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="potential-outcomes.html"><a href="potential-outcomes.html#assumptions-for-identifying-causal-effects"><i class="fa fa-check"></i><b>2.2</b> Assumptions for Identifying Causal Effects</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="potential-outcomes.html"><a href="potential-outcomes.html#independence"><i class="fa fa-check"></i><b>2.2.1</b> <strong>Independence</strong></a></li>
<li class="chapter" data-level="2.2.2" data-path="potential-outcomes.html"><a href="potential-outcomes.html#stable-unit-treatment-value-assumption-sutva"><i class="fa fa-check"></i><b>2.2.2</b> Stable Unit Treatment Value Assumption (SUTVA)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="potential-outcomes.html"><a href="potential-outcomes.html#methods-for-estimating-causal-effects"><i class="fa fa-check"></i><b>2.3</b> Methods for Estimating Causal Effects</a></li>
<li class="chapter" data-level="2.4" data-path="potential-outcomes.html"><a href="potential-outcomes.html#example"><i class="fa fa-check"></i><b>2.4</b> Example</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="potential-outcomes.html"><a href="potential-outcomes.html#simple-difference-method"><i class="fa fa-check"></i><b>2.4.1</b> Simple Difference Method</a></li>
<li class="chapter" data-level="2.4.2" data-path="potential-outcomes.html"><a href="potential-outcomes.html#conclusion"><i class="fa fa-check"></i><b>2.4.2</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="matching.html"><a href="matching.html"><i class="fa fa-check"></i><b>3</b> Matching</a>
<ul>
<li class="chapter" data-level="3.1" data-path="matching.html"><a href="matching.html#subclassification"><i class="fa fa-check"></i><b>3.1</b> Subclassification</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="matching.html"><a href="matching.html#example-2"><i class="fa fa-check"></i><b>3.1.1</b> Example</a></li>
<li class="chapter" data-level="3.1.2" data-path="matching.html"><a href="matching.html#step-by-step-example"><i class="fa fa-check"></i><b>3.1.2</b> Step-by-Step Example</a></li>
<li class="chapter" data-level="3.1.3" data-path="matching.html"><a href="matching.html#considerations"><i class="fa fa-check"></i><b>3.1.3</b> Considerations</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="matching.html"><a href="matching.html#exact-matching"><i class="fa fa-check"></i><b>3.2</b> Exact Matching</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="matching.html"><a href="matching.html#explanation"><i class="fa fa-check"></i><b>3.2.1</b> Explanation</a></li>
<li class="chapter" data-level="3.2.2" data-path="matching.html"><a href="matching.html#example-3"><i class="fa fa-check"></i><b>3.2.2</b> Example</a></li>
<li class="chapter" data-level="3.2.3" data-path="matching.html"><a href="matching.html#conclusion-1"><i class="fa fa-check"></i><b>3.2.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="matching.html"><a href="matching.html#approximate-matching-methods"><i class="fa fa-check"></i><b>3.3</b> Approximate Matching Methods</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="matching.html"><a href="matching.html#nearest-neighbor-covariate-matching"><i class="fa fa-check"></i><b>3.3.1</b> Nearest Neighbor Covariate Matching</a></li>
<li class="chapter" data-level="3.3.2" data-path="matching.html"><a href="matching.html#example-4"><i class="fa fa-check"></i><b>3.3.2</b> Example</a></li>
<li class="chapter" data-level="3.3.3" data-path="matching.html"><a href="matching.html#hypothetical-data"><i class="fa fa-check"></i><b>3.3.3</b> Hypothetical Data</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="matching.html"><a href="matching.html#propensity-score-methods"><i class="fa fa-check"></i><b>3.4</b> Propensity Score Methods</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="matching.html"><a href="matching.html#concept"><i class="fa fa-check"></i><b>3.4.1</b> Concept</a></li>
<li class="chapter" data-level="3.4.2" data-path="matching.html"><a href="matching.html#steps"><i class="fa fa-check"></i><b>3.4.2</b> Steps</a></li>
<li class="chapter" data-level="3.4.3" data-path="matching.html"><a href="matching.html#example-5"><i class="fa fa-check"></i><b>3.4.3</b> Example</a></li>
<li class="chapter" data-level="3.4.4" data-path="matching.html"><a href="matching.html#assumptions-and-considerations"><i class="fa fa-check"></i><b>3.4.4</b> Assumptions and Considerations</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="matching.html"><a href="matching.html#inverse-probability-weighting-weighting-on-the-propensity-score"><i class="fa fa-check"></i><b>3.5</b> Inverse Probability Weighting (Weighting on the propensity score)</a></li>
<li class="chapter" data-level="3.6" data-path="matching.html"><a href="matching.html#nearest-neighbor-matching"><i class="fa fa-check"></i><b>3.6</b> Nearest-neighbor matching</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="matching.html"><a href="matching.html#example-in-r"><i class="fa fa-check"></i><b>3.6.1</b> Example in R</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="matching.html"><a href="matching.html#coarsened-exact-matching"><i class="fa fa-check"></i><b>3.7</b> Coarsened Exact Matching</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="matching.html"><a href="matching.html#example-6"><i class="fa fa-check"></i><b>3.7.1</b> Example</a></li>
<li class="chapter" data-level="3.7.2" data-path="matching.html"><a href="matching.html#steps-in-coarsened-exact-matching"><i class="fa fa-check"></i><b>3.7.2</b> Steps in Coarsened Exact Matching</a></li>
<li class="chapter" data-level="3.7.3" data-path="matching.html"><a href="matching.html#considerations-1"><i class="fa fa-check"></i><b>3.7.3</b> Considerations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ab-testing.html"><a href="ab-testing.html"><i class="fa fa-check"></i><b>4</b> AB Testing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ab-testing.html"><a href="ab-testing.html#sources"><i class="fa fa-check"></i><b>4.1</b> Sources</a></li>
<li class="chapter" data-level="4.2" data-path="ab-testing.html"><a href="ab-testing.html#concepts-1"><i class="fa fa-check"></i><b>4.2</b> Concepts</a></li>
<li class="chapter" data-level="4.3" data-path="ab-testing.html"><a href="ab-testing.html#ai-summary"><i class="fa fa-check"></i><b>4.3</b> AI Summary</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ab-testing.html"><a href="ab-testing.html#ab-testing-randomized-controlled-trials"><i class="fa fa-check"></i><b>4.3.1</b> A/B Testing (Randomized Controlled Trials)</a></li>
<li class="chapter" data-level="4.3.2" data-path="ab-testing.html"><a href="ab-testing.html#concepts-2"><i class="fa fa-check"></i><b>4.3.2</b> Concepts:</a></li>
<li class="chapter" data-level="4.3.3" data-path="ab-testing.html"><a href="ab-testing.html#comparison-and-usage"><i class="fa fa-check"></i><b>4.3.3</b> Comparison and Usage</a></li>
<li class="chapter" data-level="4.3.4" data-path="ab-testing.html"><a href="ab-testing.html#significance"><i class="fa fa-check"></i><b>4.3.4</b> Significance</a></li>
<li class="chapter" data-level="4.3.5" data-path="ab-testing.html"><a href="ab-testing.html#group-size"><i class="fa fa-check"></i><b>4.3.5</b> Group Size</a></li>
<li class="chapter" data-level="4.3.6" data-path="ab-testing.html"><a href="ab-testing.html#relationship-between-effect-size-significance-and-group-size"><i class="fa fa-check"></i><b>4.3.6</b> Relationship Between Effect Size, Significance, and Group Size</a></li>
<li class="chapter" data-level="4.3.7" data-path="ab-testing.html"><a href="ab-testing.html#conclusion-2"><i class="fa fa-check"></i><b>4.3.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ab-testing.html"><a href="ab-testing.html#size-of-the-control-group"><i class="fa fa-check"></i><b>4.4</b> Size of the Control Group</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ab-testing.html"><a href="ab-testing.html#sample-size-calculation-formula"><i class="fa fa-check"></i><b>4.4.1</b> Sample Size Calculation Formula</a></li>
<li class="chapter" data-level="4.4.2" data-path="ab-testing.html"><a href="ab-testing.html#conclusion-3"><i class="fa fa-check"></i><b>4.4.2</b> Conclusion</a></li>
<li class="chapter" data-level="4.4.3" data-path="ab-testing.html"><a href="ab-testing.html#statistical-assumptions-for-randomized-controlled-trials-rcts"><i class="fa fa-check"></i><b>4.4.3</b> Statistical Assumptions for Randomized Controlled Trials (RCTs)</a></li>
<li class="chapter" data-level="4.4.4" data-path="ab-testing.html"><a href="ab-testing.html#robustness-checks-1"><i class="fa fa-check"></i><b>4.4.4</b> Robustness Checks</a></li>
<li class="chapter" data-level="4.4.5" data-path="ab-testing.html"><a href="ab-testing.html#validation-methods-1"><i class="fa fa-check"></i><b>4.4.5</b> Validation Methods</a></li>
<li class="chapter" data-level="4.4.6" data-path="ab-testing.html"><a href="ab-testing.html#conclusion-4"><i class="fa fa-check"></i><b>4.4.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ab-testing.html"><a href="ab-testing.html#example-conversion-rate-of-an-e-commerce-website"><i class="fa fa-check"></i><b>4.5</b> Example: Conversion Rate of an E-Commerce Website</a></li>
<li class="chapter" data-level="4.6" data-path="ab-testing.html"><a href="ab-testing.html#example-ab-test"><i class="fa fa-check"></i><b>4.6</b> Example: A/B Test</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="ab-testing.html"><a href="ab-testing.html#task-1-load-the-data"><i class="fa fa-check"></i><b>4.6.1</b> Task 1: Load the data</a></li>
<li class="chapter" data-level="4.6.2" data-path="ab-testing.html"><a href="ab-testing.html#task-2-set-up-hypothesis"><i class="fa fa-check"></i><b>4.6.2</b> Task 2: Set up Hypothesis</a></li>
<li class="chapter" data-level="4.6.3" data-path="ab-testing.html"><a href="ab-testing.html#task-3-compute-the-difference-in-the-click-through-rate"><i class="fa fa-check"></i><b>4.6.3</b> Task 3: Compute the difference in the click-through rate</a></li>
<li class="chapter" data-level="4.6.4" data-path="ab-testing.html"><a href="ab-testing.html#task-four-create-sample-distribution-using-bootsrapping"><i class="fa fa-check"></i><b>4.6.4</b> Task four : create sample distribution using bootsrapping</a></li>
<li class="chapter" data-level="4.6.5" data-path="ab-testing.html"><a href="ab-testing.html#task-five-evaluate-the-null-hypothesis-and-draw-conclustions."><i class="fa fa-check"></i><b>4.6.5</b> Task five : Evaluate the null hypothesis and draw conclustions.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html"><i class="fa fa-check"></i><b>5</b> Difference-in-Differences (DiD) Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#simple-difference-in-differences-did"><i class="fa fa-check"></i><b>5.1</b> Simple Difference-in-Differences (DiD)</a></li>
<li class="chapter" data-level="5.2" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#controversial-note"><i class="fa fa-check"></i><b>5.2</b> Controversial Note</a></li>
<li class="chapter" data-level="5.3" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#placebo-tests-for-parallel-trends"><i class="fa fa-check"></i><b>5.3</b> Placebo tests for parallel trends</a></li>
<li class="chapter" data-level="5.4" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#two-way-fixed-effects-model"><i class="fa fa-check"></i><b>5.4</b> Two-Way Fixed Effects Model</a></li>
<li class="chapter" data-level="5.5" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#event-study-methods"><i class="fa fa-check"></i><b>5.5</b> Event Study Methods</a></li>
<li class="chapter" data-level="5.6" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#importance-of-placebos-in-dd"><i class="fa fa-check"></i><b>5.6</b> Importance of Placebos in DD</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#triple-differences"><i class="fa fa-check"></i><b>5.6.1</b> Triple Differences</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#compositional-changes"><i class="fa fa-check"></i><b>5.7</b> Compositional Changes</a></li>
<li class="chapter" data-level="5.8" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#key-assumptions"><i class="fa fa-check"></i><b>5.8</b> Key Assumptions</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#implementation-steps"><i class="fa fa-check"></i><b>5.8.1</b> Implementation Steps</a></li>
<li class="chapter" data-level="5.8.2" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#advantages"><i class="fa fa-check"></i><b>5.8.2</b> Advantages</a></li>
<li class="chapter" data-level="5.8.3" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#limitations-1"><i class="fa fa-check"></i><b>5.8.3</b> Limitations</a></li>
<li class="chapter" data-level="5.8.4" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#q-how-would-you-test-the-parallel-trends-assumption"><i class="fa fa-check"></i><b>5.8.4</b> Q: How would you test the parallel trends assumption?</a></li>
<li class="chapter" data-level="5.8.5" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#q-how-would-you-address-potential-violations-of-the-parallel-trends-assumption"><i class="fa fa-check"></i><b>5.8.5</b> Q: How would you address potential violations of the parallel trends assumption?</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#notes"><i class="fa fa-check"></i><b>5.9</b> Notes</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#example-business"><i class="fa fa-check"></i><b>5.9.1</b> Example: Business</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#extra-considerations"><i class="fa fa-check"></i><b>5.10</b> Extra Considerations</a></li>
<li class="chapter" data-level="5.11" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#synthetic-difference-in-differences-synthdid-method"><i class="fa fa-check"></i><b>5.11</b> Synthetic Difference-in-Differences (SynthDiD) method</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#introduction"><i class="fa fa-check"></i><b>5.11.1</b> Introduction</a></li>
<li class="chapter" data-level="5.11.2" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#what-problem-it-solves"><i class="fa fa-check"></i><b>5.11.2</b> What problem it solves</a></li>
<li class="chapter" data-level="5.11.3" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#how-it-works-intuition"><i class="fa fa-check"></i><b>5.11.3</b> How it works (intuition)</a></li>
<li class="chapter" data-level="5.11.4" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#how-it-differs-from-related-methods"><i class="fa fa-check"></i><b>5.11.4</b> How it differs from related methods</a></li>
<li class="chapter" data-level="5.11.5" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#when-to-use"><i class="fa fa-check"></i><b>5.11.5</b> When to use</a></li>
<li class="chapter" data-level="5.11.6" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#assumptions-why-its-appealing"><i class="fa fa-check"></i><b>5.11.6</b> Assumptions (why it’s appealing)</a></li>
<li class="chapter" data-level="5.11.7" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#inference-diagnostics"><i class="fa fa-check"></i><b>5.11.7</b> Inference &amp; diagnostics</a></li>
<li class="chapter" data-level="5.11.8" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#pros-cons"><i class="fa fa-check"></i><b>5.11.8</b> Pros / Cons</a></li>
<li class="chapter" data-level="5.11.9" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#tldr-contrast"><i class="fa fa-check"></i><b>5.11.9</b> TL;DR (contrast)</a></li>
<li class="chapter" data-level="5.11.10" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#an-example"><i class="fa fa-check"></i><b>5.11.10</b> An Example:</a></li>
<li class="chapter" data-level="5.11.11" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#conclusion-5"><i class="fa fa-check"></i><b>5.11.11</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#doubly-robust-difference-in-differences"><i class="fa fa-check"></i><b>5.12</b> Doubly Robust Difference in Differences</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#details"><i class="fa fa-check"></i><b>5.12.1</b> Details</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#twoway-fixed-effects-with-differential-timing"><i class="fa fa-check"></i><b>5.13</b> Twoway Fixed Effects with Differential Timing</a></li>
<li class="chapter" data-level="5.14" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#bacon-decomposition"><i class="fa fa-check"></i><b>5.14</b> Bacon Decomposition</a>
<ul>
<li class="chapter" data-level="5.14.1" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#overview"><i class="fa fa-check"></i><b>5.14.1</b> Overview</a></li>
<li class="chapter" data-level="5.14.2" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#key-concepts-3"><i class="fa fa-check"></i><b>5.14.2</b> Key Concepts</a></li>
<li class="chapter" data-level="5.14.3" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#components-of-bacon-decomposition"><i class="fa fa-check"></i><b>5.14.3</b> Components of Bacon Decomposition</a></li>
<li class="chapter" data-level="5.14.4" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#formula-for-decomposition"><i class="fa fa-check"></i><b>5.14.4</b> Formula for Decomposition</a></li>
<li class="chapter" data-level="5.14.5" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#implications-and-interpretation"><i class="fa fa-check"></i><b>5.14.5</b> Implications and Interpretation</a></li>
<li class="chapter" data-level="5.14.6" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#example-8"><i class="fa fa-check"></i><b>5.14.6</b> Example</a></li>
<li class="chapter" data-level="5.14.7" data-path="difference-in-differences-did-methods.html"><a href="difference-in-differences-did-methods.html#conclusion-6"><i class="fa fa-check"></i><b>5.14.7</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html"><i class="fa fa-check"></i><b>6</b> Synthetic Control Method (SCM)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#ai-summary-1"><i class="fa fa-check"></i><b>6.1</b> AI Summary</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#synthetic-control-method-scm-1"><i class="fa fa-check"></i><b>6.1.1</b> Synthetic Control Method (SCM)</a></li>
<li class="chapter" data-level="6.1.2" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#placebo-tests"><i class="fa fa-check"></i><b>6.1.2</b> Placebo tests</a></li>
<li class="chapter" data-level="6.1.3" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>6.1.3</b> Leave-One-Out Cross-Validation</a></li>
<li class="chapter" data-level="6.1.4" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#detailed-example"><i class="fa fa-check"></i><b>6.1.4</b> Detailed Example</a></li>
<li class="chapter" data-level="6.1.5" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#conclusion-8"><i class="fa fa-check"></i><b>6.1.5</b> Conclusion</a></li>
<li class="chapter" data-level="6.1.6" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#data"><i class="fa fa-check"></i><b>6.1.6</b> Data</a></li>
<li class="chapter" data-level="6.1.7" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#data-setting"><i class="fa fa-check"></i><b>6.1.7</b> Data Setting</a></li>
<li class="chapter" data-level="6.1.8" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#requirements-for-synthetic-control-method"><i class="fa fa-check"></i><b>6.1.8</b> Requirements for Synthetic Control Method</a></li>
<li class="chapter" data-level="6.1.9" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#data-requirements-summary"><i class="fa fa-check"></i><b>6.1.9</b> Data Requirements Summary</a></li>
<li class="chapter" data-level="6.1.10" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#practical-considerations"><i class="fa fa-check"></i><b>6.1.10</b> Practical Considerations</a></li>
<li class="chapter" data-level="6.1.11" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#example-11"><i class="fa fa-check"></i><b>6.1.11</b> Example</a></li>
<li class="chapter" data-level="6.1.12" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#conclusion-9"><i class="fa fa-check"></i><b>6.1.12</b> Conclusion</a></li>
<li class="chapter" data-level="6.1.13" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#synthetic-did"><i class="fa fa-check"></i><b>6.1.13</b> Synthetic DID</a></li>
<li class="chapter" data-level="6.1.14" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#robustness-checks-3"><i class="fa fa-check"></i><b>6.1.14</b> Robustness Checks</a></li>
<li class="chapter" data-level="6.1.15" data-path="synthetic-control-method-scm.html"><a href="synthetic-control-method-scm.html#validation-methods-3"><i class="fa fa-check"></i><b>6.1.15</b> Validation Methods</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html"><i class="fa fa-check"></i><b>7</b> Instrumental Variables (IV)</a>
<ul>
<li class="chapter" data-level="7.1" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#key-concepts-4"><i class="fa fa-check"></i><b>7.1</b> Key Concepts</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#requirements-for-a-valid-instrument"><i class="fa fa-check"></i><b>7.1.1</b> Requirements for a Valid Instrument</a></li>
<li class="chapter" data-level="7.1.2" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#the-iv-estimation-process"><i class="fa fa-check"></i><b>7.1.2</b> The IV Estimation Process</a></li>
<li class="chapter" data-level="7.1.3" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#example-12"><i class="fa fa-check"></i><b>7.1.3</b> Example</a></li>
<li class="chapter" data-level="7.1.4" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#assumptions-and-considerations-1"><i class="fa fa-check"></i><b>7.1.4</b> Assumptions and Considerations</a></li>
<li class="chapter" data-level="7.1.5" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#advantages-of-iv"><i class="fa fa-check"></i><b>7.1.5</b> Advantages of IV</a></li>
<li class="chapter" data-level="7.1.6" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#disadvantages-of-iv"><i class="fa fa-check"></i><b>7.1.6</b> Disadvantages of IV</a></li>
<li class="chapter" data-level="7.1.7" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#conclusion-10"><i class="fa fa-check"></i><b>7.1.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#difference-between-instrumental-variable-iv-method-and-two-stage-least-squares-2sls-method"><i class="fa fa-check"></i><b>7.2</b> Difference Between Instrumental Variable (IV) Method and Two-Stage Least Squares (2SLS) Method</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#instrumental-variable-iv-method"><i class="fa fa-check"></i><b>7.2.1</b> Instrumental Variable (IV) Method</a></li>
<li class="chapter" data-level="7.2.2" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#two-stage-least-squares-2sls-method"><i class="fa fa-check"></i><b>7.2.2</b> Two-Stage Least Squares (2SLS) Method</a></li>
<li class="chapter" data-level="7.2.3" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#summary-of-differences"><i class="fa fa-check"></i><b>7.2.3</b> Summary of Differences:</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#homogenous-treatment-effect"><i class="fa fa-check"></i><b>7.3</b> Homogenous Treatment Effect</a></li>
<li class="chapter" data-level="7.4" data-path="instrumental-variables-iv.html"><a href="instrumental-variables-iv.html#heterogenous-treatment-effect"><i class="fa fa-check"></i><b>7.4</b> Heterogenous Treatment Effect</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html"><i class="fa fa-check"></i><b>8</b> Regression Discontinuity Designs (RDD)</a>
<ul>
<li class="chapter" data-level="8.0.1" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#validation-and-falsification"><i class="fa fa-check"></i><b>8.0.1</b> Validation and Falsification</a></li>
<li class="chapter" data-level="8.1" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#regression-discontinuity-designs-rdd-1"><i class="fa fa-check"></i><b>8.1</b> Regression Discontinuity Designs (RDD)</a></li>
<li class="chapter" data-level="8.2" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#key-concepts-5"><i class="fa fa-check"></i><b>8.2</b> Key Concepts</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#types-of-rdd"><i class="fa fa-check"></i><b>8.2.1</b> Types of RDD</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#sharp-rdd"><i class="fa fa-check"></i><b>8.3</b> Sharp RDD</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#key-concepts-6"><i class="fa fa-check"></i><b>8.3.1</b> Key Concepts</a></li>
<li class="chapter" data-level="8.3.2" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#assumptions-for-rdd"><i class="fa fa-check"></i><b>8.3.2</b> Assumptions for RDD</a></li>
<li class="chapter" data-level="8.3.3" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#estimation-in-sharp-rdd"><i class="fa fa-check"></i><b>8.3.3</b> Estimation in Sharp RDD</a></li>
<li class="chapter" data-level="8.3.4" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#fuzzy-rdd"><i class="fa fa-check"></i><b>8.3.4</b> Fuzzy RDD</a></li>
<li class="chapter" data-level="8.3.5" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#parametric-vs.-non-parametric-applications"><i class="fa fa-check"></i><b>8.3.5</b> Parametric vs. Non-Parametric Applications</a></li>
<li class="chapter" data-level="8.3.6" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#example-13"><i class="fa fa-check"></i><b>8.3.6</b> Example</a></li>
<li class="chapter" data-level="8.3.7" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#summary-3"><i class="fa fa-check"></i><b>8.3.7</b> Summary</a></li>
<li class="chapter" data-level="8.3.8" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#challenges-to-identification"><i class="fa fa-check"></i><b>8.3.8</b> Challenges to Identification</a></li>
<li class="chapter" data-level="8.3.9" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#examples-1"><i class="fa fa-check"></i><b>8.3.9</b> Examples</a></li>
<li class="chapter" data-level="8.3.10" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#types-of-rdd-1"><i class="fa fa-check"></i><b>8.3.10</b> Types of RDD</a></li>
<li class="chapter" data-level="8.3.11" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#parametric-vs.-non-parametric-applications-1"><i class="fa fa-check"></i><b>8.3.11</b> Parametric vs. Non-Parametric Applications</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regression-discontinuity-designs-rdd.html"><a href="regression-discontinuity-designs-rdd.html#regression-kink-design"><i class="fa fa-check"></i><b>8.4</b> Regression Kink Design</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html"><i class="fa fa-check"></i><b>9</b> Doubly Robust Methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#why-they-matter"><i class="fa fa-check"></i><b>9.1</b> Why They Matter</a></li>
<li class="chapter" data-level="9.2" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#core-ingredients"><i class="fa fa-check"></i><b>9.2</b> Core Ingredients</a></li>
<li class="chapter" data-level="9.3" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#more-on-outcome-models-for-treated-and-control"><i class="fa fa-check"></i><b>9.3</b> More on Outcome Models for Treated and Control</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#why-some-articles-emphasize-separate-models"><i class="fa fa-check"></i><b>9.3.1</b> Why Some Articles Emphasize Separate Models</a></li>
<li class="chapter" data-level="9.3.2" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#key-point"><i class="fa fa-check"></i><b>9.3.2</b> Key Point</a></li>
<li class="chapter" data-level="9.3.3" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#takeaway-for-your-notebook"><i class="fa fa-check"></i><b>9.3.3</b> Takeaway for Your Notebook</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#advantages-1"><i class="fa fa-check"></i><b>9.4</b> Advantages</a></li>
<li class="chapter" data-level="9.5" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#assumptions-2"><i class="fa fa-check"></i><b>9.5</b> Assumptions</a></li>
<li class="chapter" data-level="9.6" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#example-applications"><i class="fa fa-check"></i><b>9.6</b> Example Applications</a></li>
<li class="chapter" data-level="9.7" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#summary-4"><i class="fa fa-check"></i><b>9.7</b> Summary</a></li>
<li class="chapter" data-level="9.8" data-path="doubly-robust-methods.html"><a href="doubly-robust-methods.html#extension-dr-in-difference-in-differences-drdid"><i class="fa fa-check"></i><b>9.8</b> Extension: DR in Difference-in-Differences (DRDID)</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html"><i class="fa fa-check"></i><b>10</b> Double/Debiased Machine Learning (Double ML)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#motivation"><i class="fa fa-check"></i><b>10.1</b> Motivation</a></li>
<li class="chapter" data-level="10.2" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#key-components"><i class="fa fa-check"></i><b>10.2</b> Key Components</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#practical-workflow"><i class="fa fa-check"></i><b>10.2.1</b> Practical Workflow</a></li>
<li class="chapter" data-level="10.2.2" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#use-case-example"><i class="fa fa-check"></i><b>10.2.2</b> Use Case Example</a></li>
<li class="chapter" data-level="10.2.3" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#advantages-2"><i class="fa fa-check"></i><b>10.2.3</b> Advantages</a></li>
<li class="chapter" data-level="10.2.4" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#key-reference"><i class="fa fa-check"></i><b>10.2.4</b> Key Reference</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#doubly-robust-dr-vs.-double-machine-learning-dml"><i class="fa fa-check"></i><b>10.3</b> Doubly Robust (DR) vs. Double Machine Learning (DML)</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#key-takeaway"><i class="fa fa-check"></i><b>10.3.1</b> Key Takeaway</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#concepts-3"><i class="fa fa-check"></i><b>10.4</b> Concepts</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#nuisance-functions"><i class="fa fa-check"></i><b>10.4.1</b> 🔹 Nuisance Functions</a></li>
<li class="chapter" data-level="10.4.2" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#orthogonalization"><i class="fa fa-check"></i><b>10.4.2</b> 🔹 Orthogonalization</a></li>
<li class="chapter" data-level="10.4.3" data-path="doubledebiased-machine-learning-double-ml.html"><a href="doubledebiased-machine-learning-double-ml.html#why-this-matters"><i class="fa fa-check"></i><b>10.4.3</b> 🔹 Why This Matters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html"><i class="fa fa-check"></i><b>11</b> Ordinary Least Squares (OLS)</a>
<ul>
<li class="chapter" data-level="11.0.1" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#linearity"><i class="fa fa-check"></i><b>11.0.1</b> <strong>Linearity</strong></a></li>
<li class="chapter" data-level="11.0.2" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#exogeneity"><i class="fa fa-check"></i><b>11.0.2</b> <strong>Exogeneity</strong></a></li>
<li class="chapter" data-level="11.0.3" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#homoscedasticity"><i class="fa fa-check"></i><b>11.0.3</b> <strong>Homoscedasticity</strong></a></li>
<li class="chapter" data-level="11.0.4" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#no-autocorrelation"><i class="fa fa-check"></i><b>11.0.4</b> <strong>No Autocorrelation</strong></a></li>
<li class="chapter" data-level="11.0.5" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#no-perfect-multicollinearity"><i class="fa fa-check"></i><b>11.0.5</b> <strong>No Perfect Multicollinearity</strong></a></li>
<li class="chapter" data-level="11.0.6" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#normality-of-errors-for-inference"><i class="fa fa-check"></i><b>11.0.6</b> <strong>Normality of Errors (for inference)</strong></a></li>
<li class="chapter" data-level="11.0.7" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#practical-considerations-and-tests"><i class="fa fa-check"></i><b>11.0.7</b> Practical Considerations and Tests</a></li>
<li class="chapter" data-level="11.1" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#simple-linear-regression"><i class="fa fa-check"></i><b>11.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#summary-5"><i class="fa fa-check"></i><b>11.1.1</b> Summary</a></li>
<li class="chapter" data-level="11.1.2" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#interpreting-model-coefficients-in-ols-models"><i class="fa fa-check"></i><b>11.1.2</b> Interpreting Model Coefficients in OLS Models</a></li>
<li class="chapter" data-level="11.1.3" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#linear-models-linear-linear"><i class="fa fa-check"></i><b>11.1.3</b> 1. Linear Models (Linear-Linear)</a></li>
<li class="chapter" data-level="11.1.4" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#log-linear-models"><i class="fa fa-check"></i><b>11.1.4</b> 2. Log-Linear Models</a></li>
<li class="chapter" data-level="11.1.5" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#linear-log-models"><i class="fa fa-check"></i><b>11.1.5</b> 3. Linear-Log Models</a></li>
<li class="chapter" data-level="11.1.6" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#log-log-models"><i class="fa fa-check"></i><b>11.1.6</b> 4. Log-Log Models</a></li>
<li class="chapter" data-level="11.1.7" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#examples-of-dummy-and-continuous-variables"><i class="fa fa-check"></i><b>11.1.7</b> Examples of Dummy and Continuous Variables</a></li>
<li class="chapter" data-level="11.1.8" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#assumptions-and-considerations-2"><i class="fa fa-check"></i><b>11.1.8</b> Assumptions and Considerations</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#multivariate-regression"><i class="fa fa-check"></i><b>11.2</b> Multivariate Regression</a></li>
<li class="chapter" data-level="11.3" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#generalized-linear-model"><i class="fa fa-check"></i><b>11.3</b> Generalized Linear Model</a></li>
<li class="chapter" data-level="11.4" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#generalised-least-square"><i class="fa fa-check"></i><b>11.4</b> Generalised Least Square</a></li>
<li class="chapter" data-level="11.5" data-path="ordinary-least-squares-ols.html"><a href="ordinary-least-squares-ols.html#weighted-least-squares-wls"><i class="fa fa-check"></i><b>11.5</b> Weighted Least Squares (WLS)</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>12</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="logistic-regression.html"><a href="logistic-regression.html#model"><i class="fa fa-check"></i><b>12.1</b> Model</a></li>
<li class="chapter" data-level="12.2" data-path="logistic-regression.html"><a href="logistic-regression.html#estimation"><i class="fa fa-check"></i><b>12.2</b> Estimation</a></li>
<li class="chapter" data-level="12.3" data-path="logistic-regression.html"><a href="logistic-regression.html#hypothesis-testing"><i class="fa fa-check"></i><b>12.3</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="12.4" data-path="logistic-regression.html"><a href="logistic-regression.html#role-in-causal-inference"><i class="fa fa-check"></i><b>12.4</b> Role in Causal Inference</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html"><i class="fa fa-check"></i><b>13</b> Hypotheis Testing</a>
<ul>
<li class="chapter" data-level="13.1" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#concepts-4"><i class="fa fa-check"></i><b>13.1</b> Concepts</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#significance-level-α"><i class="fa fa-check"></i><b>13.1.1</b> Significance Level (α)</a></li>
<li class="chapter" data-level="13.1.2" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#p-value"><i class="fa fa-check"></i><b>13.1.2</b> P-Value</a></li>
<li class="chapter" data-level="13.1.3" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#type-i-error"><i class="fa fa-check"></i><b>13.1.3</b> Type I Error</a></li>
<li class="chapter" data-level="13.1.4" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#type-ii-error"><i class="fa fa-check"></i><b>13.1.4</b> Type II Error</a></li>
<li class="chapter" data-level="13.1.5" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#relationship-between-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>13.1.5</b> Relationship Between Type I and Type II Errors</a></li>
<li class="chapter" data-level="13.1.6" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#importance-in-research-and-decision-making"><i class="fa fa-check"></i><b>13.1.6</b> Importance in Research and Decision Making</a></li>
<li class="chapter" data-level="13.1.7" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#statistical-power"><i class="fa fa-check"></i><b>13.1.7</b> Statistical power</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#null-hypothesis"><i class="fa fa-check"></i><b>13.2</b> Null Hypothesis</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#fishers-sharp-null-hypothesis"><i class="fa fa-check"></i><b>13.2.1</b> Fisher’s Sharp Null Hypothesis</a></li>
<li class="chapter" data-level="13.2.2" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#neymans-null-hypothesis"><i class="fa fa-check"></i><b>13.2.2</b> Neyman’s Null Hypothesis</a></li>
<li class="chapter" data-level="13.2.3" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#key-differences"><i class="fa fa-check"></i><b>13.2.3</b> Key Differences</a></li>
<li class="chapter" data-level="13.2.4" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#example-to-illustrate-the-difference"><i class="fa fa-check"></i><b>13.2.4</b> Example to Illustrate the Difference</a></li>
<li class="chapter" data-level="13.2.5" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#conclusion-11"><i class="fa fa-check"></i><b>13.2.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#permutation-tests"><i class="fa fa-check"></i><b>13.3</b> Permutation Tests</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#when-and-why-to-use-permutation-tests"><i class="fa fa-check"></i><b>13.3.1</b> When and Why to Use Permutation Tests</a></li>
<li class="chapter" data-level="13.3.2" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#how-to-perform-a-permutation-test"><i class="fa fa-check"></i><b>13.3.2</b> How to Perform a Permutation Test</a></li>
<li class="chapter" data-level="13.3.3" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#example-calculation"><i class="fa fa-check"></i><b>13.3.3</b> Example Calculation</a></li>
<li class="chapter" data-level="13.3.4" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#conclusion-12"><i class="fa fa-check"></i><b>13.3.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#fischers-exact-test"><i class="fa fa-check"></i><b>13.4</b> Fischer’s Exact Test</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#when-to-use-fishers-exact-test"><i class="fa fa-check"></i><b>13.4.1</b> When to Use Fisher’s Exact Test</a></li>
<li class="chapter" data-level="13.4.2" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#how-fishers-exact-test-works"><i class="fa fa-check"></i><b>13.4.2</b> How Fisher’s Exact Test Works</a></li>
<li class="chapter" data-level="13.4.3" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#step-by-step-example-1"><i class="fa fa-check"></i><b>13.4.3</b> Step-by-Step Example</a></li>
<li class="chapter" data-level="13.4.4" data-path="hypotheis-testing.html"><a href="hypotheis-testing.html#conclusion-13"><i class="fa fa-check"></i><b>13.4.4</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>14</b> Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="15" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>15</b> Resampling methods</a>
<ul>
<li class="chapter" data-level="15.1" data-path="resampling-methods.html"><a href="resampling-methods.html#randomization-based-methods"><i class="fa fa-check"></i><b>15.1</b> Randomization-Based Methods</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#traditional-methods-vs.-randomization-based-methods"><i class="fa fa-check"></i><b>15.1.1</b> Traditional Methods vs. Randomization-Based Methods</a></li>
<li class="chapter" data-level="15.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#why-use-randomization-based-methods"><i class="fa fa-check"></i><b>15.1.2</b> Why Use Randomization-Based Methods?</a></li>
<li class="chapter" data-level="15.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#how-randomization-based-methods-work"><i class="fa fa-check"></i><b>15.1.3</b> How Randomization-Based Methods Work</a></li>
<li class="chapter" data-level="15.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#example-15"><i class="fa fa-check"></i><b>15.1.4</b> Example</a></li>
<li class="chapter" data-level="15.1.5" data-path="resampling-methods.html"><a href="resampling-methods.html#contribution-of-athey-and-imbens"><i class="fa fa-check"></i><b>15.1.5</b> Contribution of Athey and Imbens</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="resampling-methods.html"><a href="resampling-methods.html#bootstrapping-1"><i class="fa fa-check"></i><b>15.2</b> Bootstrapping</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html"><i class="fa fa-check"></i><b>16</b> Fixed Effects and Panel Data Methods</a>
<ul>
<li class="chapter" data-level="16.1" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html#pooled-regression"><i class="fa fa-check"></i><b>16.1</b> Pooled Regression</a></li>
<li class="chapter" data-level="16.2" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html#panel-data-methods"><i class="fa fa-check"></i><b>16.2</b> Panel Data Methods</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html#fixed-effects-model"><i class="fa fa-check"></i><b>16.2.1</b> Fixed Effects Model</a></li>
<li class="chapter" data-level="16.2.2" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html#random-effects-model"><i class="fa fa-check"></i><b>16.2.2</b> Random Effects Model</a></li>
<li class="chapter" data-level="16.2.3" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html#example-economic-growth-and-education"><i class="fa fa-check"></i><b>16.2.3</b> Example: Economic Growth and Education</a></li>
<li class="chapter" data-level="16.2.4" data-path="fixed-effects-and-panel-data-methods.html"><a href="fixed-effects-and-panel-data-methods.html#conclusion-14"><i class="fa fa-check"></i><b>16.2.4</b> Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html"><i class="fa fa-check"></i><b>17</b> Amazon Economist - Case Study - 2024</a>
<ul>
<li class="chapter" data-level="17.1" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#concept-2"><i class="fa fa-check"></i><b>17.1</b> Concept</a></li>
<li class="chapter" data-level="17.2" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#the-scenario"><i class="fa fa-check"></i><b>17.2</b> 📦 The Scenario</a></li>
<li class="chapter" data-level="17.3" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#step-1-clarify-the-business-question-and-data"><i class="fa fa-check"></i><b>17.3</b> Step 1: Clarify the Business Question and Data</a></li>
<li class="chapter" data-level="17.4" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#step-2-possible-evaluation-designs-tech-breadth"><i class="fa fa-check"></i><b>17.4</b> Step 2: Possible Evaluation Designs (Tech Breadth)</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#randomized-controlled-trial-rct"><i class="fa fa-check"></i><b>17.4.1</b> <strong>Randomized Controlled Trial (RCT)</strong></a></li>
<li class="chapter" data-level="17.4.2" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#difference-in-differences-did"><i class="fa fa-check"></i><b>17.4.2</b> <strong>Difference-in-Differences (DiD)</strong></a></li>
<li class="chapter" data-level="17.4.3" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#event-study-staggered-adoption"><i class="fa fa-check"></i><b>17.4.3</b> <strong>Event Study / Staggered Adoption</strong></a></li>
<li class="chapter" data-level="17.4.4" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#synthetic-control"><i class="fa fa-check"></i><b>17.4.4</b> <strong>Synthetic Control</strong></a></li>
<li class="chapter" data-level="17.4.5" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#propensity-score-matching-reweighting"><i class="fa fa-check"></i><b>17.4.5</b> <strong>Propensity Score Matching / Reweighting</strong></a></li>
<li class="chapter" data-level="17.4.6" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#instrumental-variables-iv-if-spillovers-or-selection-bias-is-a-concern."><i class="fa fa-check"></i><b>17.4.6</b> <strong>Instrumental Variables (IV)</strong> (if spillovers or selection bias is a concern).</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#step-3-tech-depth-example-with-difference-in-differences"><i class="fa fa-check"></i><b>17.5</b> Step 3: Tech Depth — Example with <strong>Difference-in-Differences</strong></a></li>
<li class="chapter" data-level="17.6" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#step-3-with-rcts"><i class="fa fa-check"></i><b>17.6</b> Step 3 with RCTs</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#design-choices"><i class="fa fa-check"></i><b>17.6.1</b> 🔹 Design Choices</a></li>
<li class="chapter" data-level="17.6.2" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#assumptions-3"><i class="fa fa-check"></i><b>17.6.2</b> 🔹 Assumptions</a></li>
<li class="chapter" data-level="17.6.3" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#measurement-plan"><i class="fa fa-check"></i><b>17.6.3</b> 🔹 Measurement Plan</a></li>
<li class="chapter" data-level="17.6.4" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#estimation-1"><i class="fa fa-check"></i><b>17.6.4</b> 🔹 Estimation</a></li>
<li class="chapter" data-level="17.6.5" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#power-and-sample-size"><i class="fa fa-check"></i><b>17.6.5</b> 🔹 Power and Sample Size</a></li>
<li class="chapter" data-level="17.6.6" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#threats-and-mitigations"><i class="fa fa-check"></i><b>17.6.6</b> 🔹 Threats and Mitigations</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#step-4-communicate-results"><i class="fa fa-check"></i><b>17.7</b> Step 4: Communicate Results</a></li>
<li class="chapter" data-level="17.8" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#more-on-instrumental-variables"><i class="fa fa-check"></i><b>17.8</b> More on Instrumental Variables</a></li>
<li class="chapter" data-level="17.9" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#more-questions"><i class="fa fa-check"></i><b>17.9</b> More Questions</a>
<ul>
<li class="chapter" data-level="17.9.1" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#in-ab-test-how-do-you-communicate-significance-level-change-1-5-to-non-technicals"><i class="fa fa-check"></i><b>17.9.1</b> In ab test, how do you communicate significance level change, 1%, 5% to non-technicals?</a></li>
<li class="chapter" data-level="17.9.2" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#in-synthetic-control-how-do-you-calculate-weigths"><i class="fa fa-check"></i><b>17.9.2</b> In synthetic control how do you calculate weigths?</a></li>
<li class="chapter" data-level="17.9.3" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#how-do-you-make-sure-your-analysis-is-good"><i class="fa fa-check"></i><b>17.9.3</b> How do you make sure your analysis is good?</a></li>
<li class="chapter" data-level="17.9.4" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#what-if-leadership-says-implement-his-program-in-big-cities"><i class="fa fa-check"></i><b>17.9.4</b> What if leadership says implement his program in big cities?</a></li>
<li class="chapter" data-level="17.9.5" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#what-if-leadership-want-to-do-it-within-east-and-west-coast"><i class="fa fa-check"></i><b>17.9.5</b> What if leadership want to do it within east and west coast?</a></li>
<li class="chapter" data-level="17.9.6" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#how-i-determine-sample-size-significance-and-mde"><i class="fa fa-check"></i><b>17.9.6</b> How I determine sample size, significance, and MDE</a></li>
<li class="chapter" data-level="17.9.7" data-path="amazon-economist---case-study---2024.html"><a href="amazon-economist---case-study---2024.html#how-do-you-communicate-10-15-significance-to-non-technicals"><i class="fa fa-check"></i><b>17.9.7</b> How do you communicate 10-15% significance to non-technicals</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://davutemrah.github.io" target="blank">Back to Home Page</li>
<li><a href="https://davutemrah.github.io/notebooks/" target="blank">Back to Collections</li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes on Causal Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="concepts" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> Concepts<a href="concepts.html#concepts" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="goodness-of-fit" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Goodness of Fit<a href="concepts.html#goodness-of-fit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="r-squared-r2" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> R-squared (<span class="math inline">\(R^2\)</span>)<a href="concepts.html#r-squared-r2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Measures the proportion of variation in <span class="math inline">\(y\)</span> explained by the model.</p></li>
<li><p>Useful for <strong>prediction tasks</strong>, but not for assessing causality.</p></li>
<li><p>A high <span class="math inline">\(R^2\)</span> can come from including irrelevant or even harmful controls.</p></li>
</ul>
</div>
<div id="adjusted-r-squared" class="section level3 hasAnchor" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Adjusted R-squared<a href="concepts.html#adjusted-r-squared" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Adjusts for the number of predictors; penalizes models for adding unnecessary variables.</p></li>
<li><p>Better for comparing models with different numbers of regressors, but still not a causal metric.</p></li>
</ul>
</div>
<div id="root-mean-squared-error-rmse-mean-absolute-error-mae" class="section level3 hasAnchor" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Root Mean Squared Error (RMSE) / Mean Absolute Error (MAE)<a href="concepts.html#root-mean-squared-error-rmse-mean-absolute-error-mae" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Direct measures of prediction accuracy.</p></li>
<li><p>Lower values indicate closer predictions to the actual <span class="math inline">\(y\)</span>.</p></li>
<li><p>Especially relevant when the goal is <strong>forecasting</strong> rather than causal inference.</p></li>
</ul>
</div>
<div id="aic-bic-information-criteria" class="section level3 hasAnchor" number="1.1.4">
<h3><span class="header-section-number">1.1.4</span> AIC / BIC (Information Criteria)<a href="concepts.html#aic-bic-information-criteria" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Model selection criteria that balance fit and complexity.</p></li>
<li><p>Useful when comparing non-nested models, but again, not measures of causal validity.</p></li>
</ul>
</div>
<div id="f-statistics-and-joint-significance-tests" class="section level3 hasAnchor" number="1.1.5">
<h3><span class="header-section-number">1.1.5</span> F-statistics and Joint Significance Tests<a href="concepts.html#f-statistics-and-joint-significance-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Test whether groups of variables jointly contribute explanatory power.</p></li>
<li><p>Helpful for model fit diagnostics but not sufficient for causal claims.</p></li>
</ul>
</div>
<div id="balance-checks-causal-context" class="section level3 hasAnchor" number="1.1.6">
<h3><span class="header-section-number">1.1.6</span> Balance Checks (Causal Context)<a href="concepts.html#balance-checks-causal-context" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>In causal inference, we care more about whether confounders are balanced across treatment groups than about <span class="math inline">\(R^2\)</span>.</p></li>
<li><p>Matching, weighting, or randomization checks are more informative than fit metrics.</p></li>
</ul>
</div>
<div id="key-distinction-prediction-vs.-causality" class="section level3 hasAnchor" number="1.1.7">
<h3><span class="header-section-number">1.1.7</span> Key Distinction: Prediction vs. Causality<a href="concepts.html#key-distinction-prediction-vs.-causality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="19%" />
<col width="53%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Context</strong></th>
<th><strong>Metrics that Matter</strong></th>
<th><strong>Goal</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prediction / Forecasting</td>
<td><span class="math inline">\(R^2\)</span>, Adj. <span class="math inline">\(R^2\)</span>, RMSE, MAE, AIC, BIC</td>
<td>Maximize predictive accuracy</td>
</tr>
<tr class="even">
<td>Causal Inference</td>
<td>Balance checks, robustness checks, IV strength, falsification tests</td>
<td>Identify unbiased treatment effect</td>
</tr>
</tbody>
</table>
<p>👉 <strong>Takeaway</strong>: Use <span class="math inline">\(R^2\)</span> and related metrics for <strong>prediction</strong>, but in <strong>causal inference</strong>, what matters most is whether you’ve properly handled confounders, closed backdoor paths, and used valid identification strategies.</p>
</div>
</div>
<div id="validation-methods" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Validation Methods<a href="concepts.html#validation-methods" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Definition</strong></p>
<p>Validation methods are procedures used to confirm that the analytical approach and findings are credible, correctly specified, and reliable. The goal is to ensure that the methodology captures the true causal relationship and that the results are not artifacts of flawed design or bias.</p>
<div id="internal-validity" class="section level3 hasAnchor" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Internal Validity<a href="concepts.html#internal-validity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ensures the causal estimate is <strong>credible within the study design</strong>.</p>
<p><strong>Purpose:</strong> Rule out alternative explanations for the observed effect.</p>
<p><strong>Methods:</strong></p>
<ul>
<li><p><strong>Placebo / falsification tests</strong> → Apply the method to periods or outcomes where no effect should exist. A true effect should not show up here.</p></li>
<li><p><strong>Pre-trend checks</strong> → In Difference-in-Differences (DiD), verify that treatment and control groups followed parallel trends before treatment.</p></li>
<li><p><strong>Balance tests (PSM, matching)</strong> → Confirm that covariates are similar between treated and control groups.</p></li>
<li><p><strong>Overidentification tests (IV)</strong> → If multiple instruments exist, check that they give consistent estimates.</p></li>
<li><p><strong>Sensitivity analysis</strong> → Evaluate robustness to unobserved confounders (e.g., Rosenbaum bounds).</p></li>
<li><p><strong>Resampling methods (bootstrap, cross-validation)</strong> → Ensure stability of results against sampling variation.</p></li>
</ul>
</div>
<div id="external-validity" class="section level3 hasAnchor" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> External Validity<a href="concepts.html#external-validity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ensures findings can <strong>generalize beyond the study sample</strong>.</p>
<p><strong>Purpose:</strong> Assess whether results apply to other populations, settings, or time periods.</p>
<p><strong>Methods:</strong></p>
<ul>
<li><p><strong>Benchmark comparisons</strong> → Compare effect sizes with prior literature or related experiments.</p></li>
<li><p><strong>Replication across subgroups</strong> → Test if results hold in different populations (e.g., small vs. large cities, East vs. West Coast).</p></li>
<li><p><strong>Heterogeneity analysis</strong> → Explore variation in treatment effects across demographics, regions, or time.</p></li>
<li><p><strong>Transportability / reweighting methods</strong> → Adjust sample weights so that results better reflect the target population (e.g., balancing weights to correct skewed panels).</p></li>
</ul>
<hr />
<p><strong>Why Both Matter</strong></p>
<ul>
<li><p><strong>Internal validity</strong> ensures the effect you measured is truly causal.</p></li>
<li><p><strong>External validity</strong> ensures that causal effect is useful for decision-making across broader contexts.</p></li>
</ul>
<p>Together, they strengthen the <strong>credibility, reliability, and practical relevance</strong> of your causal inference.</p>
<hr />
</div>
<div id="robustness-checks" class="section level3 hasAnchor" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Robustness Checks<a href="concepts.html#robustness-checks" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Purpose:</strong> Assess the stability of results under alternative assumptions or model choices.</p>
<p><strong>Examples:</strong></p>
<ul>
<li><p>Varying model specifications (linear vs. log, fixed effects vs. random effects).</p></li>
<li><p>Dropping outliers or trimming the sample.</p></li>
<li><p>Using alternative control groups.</p></li>
<li><p>Trying different functional forms (log of sales vs. sales level).</p></li>
<li><p>Changing time windows (short-run vs. long-run effect).</p></li>
</ul>
<p><strong>Focus:</strong> Do the results hold up if we “stress-test” the model?</p>
<hr />
<p><strong>How They Relate</strong></p>
<p>Validation asks: Did we design this study right?</p>
<p>Robustness asks: Would the results still hold if we made reasonable changes?</p>
</div>
</div>
<div id="directed-acyclic-graphs-dags" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Directed Acyclic Graphs (DAGs)<a href="concepts.html#directed-acyclic-graphs-dags" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><p>causality runs in one direction, it runs forward in time.</p></li>
<li><p>There are no cycles in a DAG. To show reverse causality, one would need to create multiple nodes, most likely with two versions of the same node separated by a time index.</p></li>
<li><p>To handle either simultaneity or reverse causality, it is recommended that you take a completely different approach to the problem than the one presented in this chapter.</p></li>
<li><p>DAGs explain causality in terms of counterfactuals. That is, a causal effect is defined as a comparison between two states of the world—one state that actually happened when some intervention took on some value and another state that didn’t happen (the “counterfactual”) under some other intervention.</p></li>
<li><p>Arrows represent a causal effect between two random variables moving in the intuitive direction of the arrow. The direction of the arrow captures the direction of causality.</p></li>
<li><p>Causal effects can happen in two ways. They can either be direct (e.g., D -&gt; Y), or they can be mediated by a third variable (e.g., D -&gt; X -&gt; Y). When they are mediated by a third variable, we are capturing a sequence of events originating with , which may or may not be important to you depending on the question you’re asking.</p></li>
<li><p>A complete DAG will have all direct causal effects among the variables in the graph as well as all common causes of any pair of variables in the graph.</p></li>
</ul>
<div id="confounder" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Confounder<a href="concepts.html#confounder" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Direct causal path:</strong>
<span class="math inline">\(D \rightarrow Y\)</span></p></li>
<li><p><strong>Backdoor (non-causal) path:</strong>
<span class="math inline">\(X \rightarrow D\)</span> and <span class="math inline">\(X \rightarrow Y\)</span></p></li>
</ul>
<p><strong>Key Idea:</strong></p>
<p>A <strong>backdoor path</strong> creates spurious correlation between <span class="math inline">\(D\)</span> (treatment) and <span class="math inline">\(Y\)</span> (outcome) that is driven only by changes in <span class="math inline">\(X\)</span> (the confounder).</p>
<ul>
<li><p>If we <strong>don’t control for <span class="math inline">\(X\)</span></strong>, the correlation between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> mixes two sources:</p>
<ol style="list-style-type: decimal">
<li><p>The <strong>true causal effect</strong> of <span class="math inline">\(D\)</span> on <span class="math inline">\(Y\)</span>.</p></li>
<li><p>The <strong>spurious association</strong> from <span class="math inline">\(X\)</span>, which influences both.</p></li>
</ol></li>
<li><p>This leads to <strong>omitted variable bias</strong> — we mistake part of $ X$’s effect for $ D$’s effect.</p></li>
</ul>
<p><strong>Definition:</strong></p>
<p>A variable <span class="math inline">\(X\)</span> is a <strong>confounder</strong> if it jointly affects both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>, making it harder to isolate the true causal effect.</p>
<p><strong>Fix:</strong></p>
<p>When <span class="math inline">\(X\)</span> is <strong>observed and included in the model</strong>, the backdoor path is <strong>closed</strong>, leaving only the direct causal relationship between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>👉 Think of it this way:</p>
<ul>
<li><p>Sometimes <span class="math inline">\(Y\)</span> changes <strong>because <span class="math inline">\(D\)</span> truly caused it</strong>.</p></li>
<li><p>Other times, <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span> both move <strong>because <span class="math inline">\(X\)</span> moved</strong>.</p></li>
<li><p>By controlling for <span class="math inline">\(X\)</span>, we separate the causal part from the spurious part.</p></li>
</ul>
</div>
<div id="collider" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Collider<a href="concepts.html#collider" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Direct causal path:</strong>
<span class="math inline">\(D \rightarrow Y\)</span></p></li>
<li><p><strong>Backdoor path:</strong>
<span class="math inline">\(D \rightarrow X \leftarrow Y\)</span></p></li>
</ul>
<p><strong>Key Idea:</strong></p>
<p>A <strong>collider</strong> is a variable influenced by both the treatment <span class="math inline">\(D\)</span> and the outcome <span class="math inline">\(Y\)</span>.</p>
<ul>
<li><p>At <span class="math inline">\(X\)</span>, the arrows from <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span> <strong>collide</strong>.</p></li>
<li><p>This means the path <span class="math inline">\(D \rightarrow X \leftarrow Y\)</span> is <strong>blocked by default</strong>.</p></li>
<li><p>So unlike confounders, <strong>colliders do not create bias</strong> when left alone.</p></li>
</ul>
<p><strong>Why It Matters:</strong></p>
<ul>
<li><p>If you <strong>do nothing</strong>, the backdoor path through a collider is closed — safe.</p></li>
<li><p>But if you <strong>control for <span class="math inline">\(X\)</span></strong> (include it in a regression, stratify, etc.), you <strong>open the path</strong>.</p>
<ul>
<li>This creates a spurious correlation between <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>, introducing <strong>collider bias</strong> (a.k.a. selection bias).</li>
</ul></li>
</ul>
<p>👉 <strong>Rule of Thumb:</strong></p>
<ul>
<li><p><strong>Control confounders</strong> → closes harmful backdoor paths.</p></li>
<li><p><strong>Do not control colliders</strong> → they’re already blocking the path.</p></li>
</ul>
</div>
<div id="what-to-do-and-how-to-do-it" class="section level3 hasAnchor" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> What To Do and How To Do It<a href="concepts.html#what-to-do-and-how-to-do-it" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>What To Do</strong></p>
<ul>
<li><p>Open <strong>backdoor paths</strong> introduce <strong>omitted variable bias</strong>. Sometimes the bias can even <strong>flip the sign</strong> of the estimated effect.</p></li>
<li><p>The goal: <strong>close all open backdoor paths</strong> so the relationship between <span class="math inline">\(D\)</span> (treatment) and <span class="math inline">\(Y\)</span> (outcome) reflects the <strong>true causal effect</strong>.</p></li>
</ul>
<p><strong>How To Do It</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>Control for Confounders</strong></p>
<ul>
<li><p>A confounder jointly affects both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>, creating an open backdoor path.</p></li>
<li><p>Close this path by <strong>conditioning on the confounder</strong> using tools like:</p>
<ul>
<li>Subclassification</li>
<li>Matching</li>
<li>Regression (include as covariates)</li>
<li>Weighting (e.g., inverse probability weights)</li>
</ul></li>
</ul></li>
<li><p><strong>Leave Colliders Alone</strong></p>
<ul>
<li>A collider is influenced by both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>.</li>
<li>By default, a backdoor path through a collider is <strong>closed</strong>.</li>
<li><strong>Conditioning on a collider opens the path</strong>, introducing <strong>collider bias</strong> (a.k.a. selection bias).</li>
<li>Strategy: <strong>do not control for colliders</strong>.</li>
</ul></li>
</ol>
<p><strong>Backdoor Criterion</strong></p>
<ul>
<li><p>If a variable is a <strong>confounder</strong> → <strong>control for it</strong>.</p></li>
<li><p>If a variable is a <strong>collider</strong> → <strong>exclude it</strong> from your model.</p></li>
</ul>
<p><strong>Rule of Thumb</strong></p>
<ul>
<li><p>Always map your variables in a <strong>causal diagram (DAG)</strong> before modeling.</p></li>
<li><p>Ask: <em>Does this variable affect both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>?</em> → confounder, control for it.</p></li>
<li><p>Ask: <em>Is this variable caused by both <span class="math inline">\(D\)</span> and <span class="math inline">\(Y\)</span>?</em> → collider, exclude it.</p></li>
</ul>
</div>
<div id="example-sample-selection-and-collider-bias" class="section level3 hasAnchor" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Example: Sample Selection and collider bias<a href="concepts.html#example-sample-selection-and-collider-bias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Imagine talent and beauty are <strong>independent traits</strong> in the general population.
However, to become a <strong>movie star</strong>, you typically need <strong>both talent and beauty</strong>.</p>
<p><strong>The Collider Effect</strong></p>
<ul>
<li><p>Here, <em>“being a movie star”</em> is a <strong>collider</strong>, because it is influenced by both <strong>talent</strong> and <strong>beauty</strong>.</p></li>
<li><p>When we <strong>condition on the collider</strong> (i.e., restrict our sample only to movie stars), we inadvertently <strong>open a backdoor path</strong> between talent and beauty.</p></li>
<li><p>As a result, talent and beauty appear <strong>negatively correlated</strong> within the movie-star sample, even though they are <strong>independent in the full population</strong>.</p></li>
</ul>
<p><strong>Why This Matters</strong></p>
<ul>
<li><p>This is an example of <strong>sample selection bias</strong>: restricting the sample on a collider introduces <strong>spurious correlations</strong>.</p></li>
<li><p>A <strong>random sample of the full population</strong> would correctly show <strong>no relationship</strong> between talent and beauty.</p></li>
<li><p>But focusing only on those who “passed through the collider” (movie stars) creates a <strong>false correlation</strong> where none exists.</p></li>
</ul>
<p>✅ <strong>Key Lesson</strong>:</p>
<p>When analyzing causal relationships, avoid conditioning on variables that act as <strong>colliders</strong>. Otherwise, you risk <strong>fabricating associations</strong> that don’t exist in reality.</p>
</div>
</div>
<div id="bad-controls" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Bad Controls<a href="concepts.html#bad-controls" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Joshua Angrist (with Guido Imbens and Jörn-Steffen Pischke) popularized the idea of <strong>“bad controls”</strong> in econometrics. These are control variables that <strong>should not</strong> be included in a regression because they distort rather than clarify the causal effect of interest.</p>
<div id="definition" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Definition<a href="concepts.html#definition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Bad controls</strong> are variables that are:</p>
<ul>
<li><strong>Post-treatment</strong> (affected by the treatment).</li>
<li>Or <strong>endogenous</strong> (correlated with unobserved factors in the error term).</li>
</ul></li>
<li><p>Including them in a model can create spurious relationships and bias causal estimates.</p></li>
</ul>
</div>
<div id="why-theyre-problematic" class="section level3 hasAnchor" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Why They’re Problematic<a href="concepts.html#why-theyre-problematic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Post-treatment controls</strong> soak up part of the treatment effect (blocking the causal path).</p></li>
<li><p><strong>Colliders</strong> open backdoor paths when conditioned on.</p></li>
<li><p><strong>Endogenous controls</strong> bias estimates because they capture unobserved shocks.</p></li>
</ul>
<p>👉 The result: biased and inconsistent causal estimates.</p>
</div>
<div id="examples" class="section level3 hasAnchor" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Examples<a href="concepts.html#examples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Education → Earnings</strong>: Controlling for <em>occupation</em> (which is partly determined by education) is a bad control.</p></li>
<li><p><strong>Treatment → Post-treatment earnings</strong>: Using post-treatment income in a regression about education biases the effect.</p></li>
<li><p><strong>Advertising campaign → Sales</strong>: Controlling for <em>brand awareness</em> (which is influenced by the campaign) is a bad control.</p></li>
</ul>
</div>
<div id="identifying-good-vs.-bad-controls" class="section level3 hasAnchor" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> Identifying Good vs. Bad Controls<a href="concepts.html#identifying-good-vs.-bad-controls" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Good controls</strong> = pre-treatment confounders: variables that affect both treatment and outcome but are not affected by the treatment.</li>
<li><strong>Bad controls</strong> = mediators, colliders, or any variable determined by treatment.</li>
</ul>
</div>
<div id="best-practices" class="section level3 hasAnchor" number="1.4.5">
<h3><span class="header-section-number">1.4.5</span> Best Practices<a href="concepts.html#best-practices" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>When choosing controls, ask:</p>
<ol style="list-style-type: decimal">
<li>Does this variable occur <strong>before</strong> the treatment?</li>
<li>Does it predict both treatment and outcome? (Confounder → include.)</li>
<li>Could it be affected by treatment? (Mediator → exclude.)</li>
<li>Is it influenced by both treatment and outcome? (Collider → exclude.)</li>
</ol></li>
<li><p>Use <strong>robustness checks</strong> to see if results hinge on questionable controls.</p></li>
</ul>
</div>
<div id="practical-advice" class="section level3 hasAnchor" number="1.4.6">
<h3><span class="header-section-number">1.4.6</span> Practical Advice<a href="concepts.html#practical-advice" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From <em>Mostly Harmless Econometrics</em>:</p>
<ul>
<li><p><em>Avoid controlling for outcomes of the treatment.</em></p></li>
<li><p><em>Focus on pre-treatment variables that help isolate causal variation.</em></p></li>
<li><p><em>Always think in terms of the causal diagram (DAG): Is the control blocking a backdoor path or accidentally opening one?</em></p></li>
</ul>
<hr />
<p>✅ This version highlights:</p>
<ul>
<li>A clear definition.</li>
<li>Why bad controls hurt causal inference.</li>
<li>Classic and business-style examples.</li>
<li>A decision rule (DAG-thinking).</li>
</ul>
</div>
<div id="unobserved-variable-affecting-only-the-dependent-variable" class="section level3 hasAnchor" number="1.4.7">
<h3><span class="header-section-number">1.4.7</span> Unobserved Variable Affecting Only the Dependent Variable<a href="concepts.html#unobserved-variable-affecting-only-the-dependent-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes there are unobserved factors that influence only the <strong>dependent variable (Y)</strong> but not the <strong>independent variables (X)</strong>. This situation is less harmful than when unobservables also affect X, but it still has consequences.</p>
<div id="no-bias-in-coefficients" class="section level4 hasAnchor" number="1.4.7.1">
<h4><span class="header-section-number">1.4.7.1</span> No Bias in Coefficients<a href="concepts.html#no-bias-in-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Since the unobserved variable doesn’t influence X, it does not create correlation between X and the error term.</p></li>
<li><p>That means <strong>no endogeneity problem</strong>: OLS estimates of the coefficients on X remain <strong>unbiased and consistent</strong>.</p></li>
</ul>
</div>
<div id="impact-on-error-variance" class="section level4 hasAnchor" number="1.4.7.2">
<h4><span class="header-section-number">1.4.7.2</span> Impact on Error Variance<a href="concepts.html#impact-on-error-variance" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>The unobserved factor shows up as “extra noise” in the error term.</li>
<li>This increases the <strong>variance of the error term</strong>, making coefficient estimates less precise.</li>
</ul>
</div>
<div id="standard-errors-and-precision" class="section level4 hasAnchor" number="1.4.7.3">
<h4><span class="header-section-number">1.4.7.3</span> Standard Errors and Precision<a href="concepts.html#standard-errors-and-precision" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Larger error variance → <strong>larger standard errors</strong> on coefficient estimates.</li>
<li>Consequence: <strong>wider confidence intervals</strong> and lower <strong>statistical power</strong> (harder to detect true effects).</li>
<li>Practically: even if your estimates are unbiased, you’re less likely to find them “statistically significant.”</li>
</ul>
</div>
<div id="summary" class="section level4 hasAnchor" number="1.4.7.4">
<h4><span class="header-section-number">1.4.7.4</span> Summary<a href="concepts.html#summary" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>✅ Estimates remain <strong>unbiased</strong>.</p></li>
<li><p>⚠️ But they are <strong>less precise</strong>.</p></li>
<li><p>Interpretation: the problem here is inefficiency, not bias. You’ll need larger samples or stronger variation in X to compensate for the added noise.</p></li>
</ul>
<p>This way, you distinguish <strong>bias vs. precision</strong> clearly — which interviewers love, since many candidates conflate the two.</p>
</div>
</div>
</div>
<div id="endogeneity" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Endogeneity<a href="concepts.html#endogeneity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Endogeneity</strong> arises when an explanatory variable is correlated with the error term in a regression. This breaks the key OLS assumption of independence between regressors and the error term, leading to biased and inconsistent estimates.</p>
<div id="sources-of-endogeneity" class="section level3 hasAnchor" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Sources of Endogeneity<a href="concepts.html#sources-of-endogeneity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Omitted Variable Bias</strong></p>
<ul>
<li>Leaving out a variable that affects both the independent and dependent variables.</li>
<li>Its effect is absorbed into the error term, creating correlation between regressors and the error.</li>
</ul></li>
<li><p><strong>Measurement Error</strong></p>
<ul>
<li>If an explanatory variable is measured with error, the “true” regressor is correlated with the measurement error (which sits in the error term).</li>
</ul></li>
<li><p><strong>Simultaneity / Reverse Causality</strong></p>
<ul>
<li>When the independent variable and dependent variable influence each other.</li>
<li>Example: advertising spend ↔︎ sales.</li>
</ul></li>
</ol>
</div>
<div id="consequences" class="section level3 hasAnchor" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Consequences<a href="concepts.html#consequences" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Biased estimates</strong>: Coefficients do not reflect the true causal effect.</p></li>
<li><p><strong>Inconsistent estimates</strong>: Even with large samples, estimates don’t converge to the true parameter.</p></li>
<li><p><strong>Threat to causal inference</strong>: We can’t trust the estimated treatment effect.</p></li>
</ul>
</div>
<div id="solutions" class="section level3 hasAnchor" number="1.5.3">
<h3><span class="header-section-number">1.5.3</span> Solutions<a href="concepts.html#solutions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Instrumental Variables (IV)</strong></p>
<ul>
<li><p>Find instruments correlated with the endogenous regressor but uncorrelated with the error term.</p></li>
<li><p>Implement using <strong>Two-Stage Least Squares (2SLS)</strong>:</p>
<ul>
<li>Stage 1: Regress endogenous regressor on instruments.</li>
<li>Stage 2: Use predicted values in the main regression.</li>
</ul></li>
</ul></li>
<li><p><strong>Fixed Effects / Panel Data</strong></p>
<ul>
<li><p>Difference out time-invariant unobservables.</p></li>
<li><p>Example: individual FE in panel regressions.</p></li>
<li><p><strong>Difference-in-Differences (DiD)</strong> as a special case: compares changes over time across treated vs. control units.</p></li>
</ul></li>
<li><p><strong>Control Function Approach</strong></p>
<ul>
<li>Include the residuals from the first-stage regression as an extra regressor to soak up endogeneity.</li>
</ul></li>
<li><p><strong>Natural Experiments</strong></p>
<ul>
<li>Use exogenous shocks (policies, disasters, lotteries) that create variation unrelated to the error term.</li>
</ul></li>
</ol>
</div>
<div id="summary-1" class="section level3 hasAnchor" number="1.5.4">
<h3><span class="header-section-number">1.5.4</span> Summary<a href="concepts.html#summary-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Endogeneity is essentially about <strong>regressors being “contaminated” by correlation with the error term</strong>.</p>
<ul>
<li>If present → OLS fails: biased + inconsistent.</li>
<li>If addressed (via IV, FE, DiD, etc.) → we can recover causal effects.</li>
</ul>
</div>
</div>
<div id="reduced-form-model" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Reduced Form Model<a href="concepts.html#reduced-form-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Reduced Form Models</strong> refer to econometric models where the endogenous variables are expressed solely in terms of exogenous variables and error terms. These models simplify the relationship between variables by avoiding the need to specify the underlying structural model, focusing instead on the observed correlations.</p>
<div id="characteristics-of-reduced-form-models" class="section level3 hasAnchor" number="1.6.1">
<h3><span class="header-section-number">1.6.1</span> Characteristics of Reduced Form Models:<a href="concepts.html#characteristics-of-reduced-form-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Simplified Representation</strong>: Reduced form models express endogenous variables directly as functions of exogenous variables and error terms.</p></li>
<li><p><strong>Focus on Exogeneity</strong>: They rely on exogenous variation to identify causal effects, avoiding direct specification of the structural relationships between variables.</p></li>
</ol>
</div>
<div id="uses-of-reduced-form-models" class="section level3 hasAnchor" number="1.6.2">
<h3><span class="header-section-number">1.6.2</span> Uses of Reduced Form Models:<a href="concepts.html#uses-of-reduced-form-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p><strong>Policy Evaluation</strong>: Reduced form models are often used in policy evaluation to estimate the causal impact of policies by leveraging exogenous variation.</p></li>
<li><p><strong>Instrumental Variables</strong>: In IV estimation, the first stage regression (predicting the endogenous variable with instruments) is a reduced form model.</p></li>
<li><p><strong>Natural Experiments</strong>: Reduced form models are frequently used in natural experiments where exogenous shocks provide a source of variation.</p></li>
</ol>
</div>
<div id="example-of-a-reduced-form-model" class="section level3 hasAnchor" number="1.6.3">
<h3><span class="header-section-number">1.6.3</span> Example of a Reduced Form Model:<a href="concepts.html#example-of-a-reduced-form-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we want to estimate the impact of education (<span class="math inline">\(E\)</span>) on earnings (<span class="math inline">\(Y\)</span>):</p>
<ol style="list-style-type: decimal">
<li><p><strong>Structural Model</strong>:
<span class="math display">\[
Y = \alpha + \beta E + \epsilon
\]</span></p></li>
<li><p><strong>Endogeneity Problem</strong>:</p>
<ul>
<li>Education (<span class="math inline">\(E\)</span>) might be endogenous due to omitted variables like ability or family background.</li>
</ul></li>
<li><p><strong>Reduced Form Model</strong>:</p>
<ul>
<li>Use an instrument <span class="math inline">\(Z\)</span> (e.g., proximity to a college) that affects education but is exogenous with respect to earnings:</li>
</ul>
<p><span class="math inline">\(E = \pi_0 + \pi_1 Z + \nu\)</span></p>
<ul>
<li>The reduced form equation for earnings in terms of the instrument:</li>
</ul>
<p><span class="math inline">\(Y = \gamma_0 + \gamma_1 Z + \eta\)</span></p></li>
</ol>
<p>Here, <span class="math inline">\(\gamma_1\)</span> provides an estimate of the causal effect of $ Z $ on $ Y $, which, under certain conditions, can be used to infer the effect of <span class="math inline">\(E\)</span> on <span class="math inline">\(Y\)</span> through <span class="math inline">\(Z\)</span>.</p>
<p>In summary, understanding and addressing endogeneity is crucial for accurate causal inference in econometrics. Reduced form models provide a simplified framework to estimate relationships using exogenous variation, often serving as a preliminary step before more complex structural modeling.</p>
</div>
</div>
<div id="standard-errors" class="section level2 hasAnchor" number="1.7">
<h2><span class="header-section-number">1.7</span> Standard Errors<a href="concepts.html#standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Homoskedasticity Assumption</strong>:</p>
<p>In linear regression, we assume that the variance of the error term is constant across all levels of the independent variables, i.e., <span class="math inline">\(Var(\epsilon | X) = \sigma^2\)</span>.</p>
<p><strong>Violation</strong>: If there is heteroscedasticity (non-constant variance of errors), the OLS estimates remain unbiased, but they are no longer efficient, and the standard errors are biased, leading to unreliable hypothesis tests. Heteroscedasticity-Robust standard errors or Generalized Least Squares (GLS) can be used to address heteroscedasticity.</p>
<ul>
<li><p>Eiker-Huber-White: Heteroscedasticity-Robust standard errors</p></li>
<li><p>Cluster-robust standard errors (geographic units)</p></li>
<li><p>Without homoskedasticity assumption, OLS estimator will still be unbiased but not efficient. Robust standard error usage will not change the OLS estimator but will change the standard errors.</p></li>
<li><p>Without constant variance, mean squared errors are not minimum anymore. Estimated standard errors are biased.</p></li>
<li><p>In real life, errors will mostly be heteroskedastic</p></li>
<li><p>Solution for heteroskedasticity is mostly known as ‘robust’ standard errors.</p></li>
</ul>
<div id="heteroskedasticity-consistent-standard-errors" class="section level3 hasAnchor" number="1.7.1">
<h3><span class="header-section-number">1.7.1</span> heteroskedasticity-consistent standard errors<a href="concepts.html#heteroskedasticity-consistent-standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Also known as robust standard errors or The sandwich standard error estimator, is a technique used to obtain valid standard errors in the presence of heteroskedasticity. These standard errors are “robust” because they do not assume that the error terms have constant variance (homoscedasticity), making them useful for hypothesis testing and confidence intervals when the usual OLS assumptions are violated.</p>
</div>
<div id="why-use-sandwich-standard-errors" class="section level3 hasAnchor" number="1.7.2">
<h3><span class="header-section-number">1.7.2</span> Why Use Sandwich Standard Errors?<a href="concepts.html#why-use-sandwich-standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In OLS regression, if the assumption of homoscedasticity is violated (i.e., the error variance is not constant), the usual standard errors of the estimated coefficients are biased. This bias can lead to incorrect inferences, such as invalid hypothesis tests and confidence intervals. Sandwich standard errors correct for this bias, providing more reliable inference.</p>
<div id="how-it-works" class="section level4 hasAnchor" number="1.7.2.1">
<h4><span class="header-section-number">1.7.2.1</span> How It Works<a href="concepts.html#how-it-works" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The sandwich estimator adjusts the standard errors of the OLS estimates to account for heteroscedasticity. The name “sandwich” comes from the structure of the formula, where the “bread” parts are the matrices that involve the model’s design matrix, and the “meat” part is a matrix involving the residuals.</p>
</div>
</div>
<div id="clustering-standard-errors" class="section level3 hasAnchor" number="1.7.3">
<h3><span class="header-section-number">1.7.3</span> Clustering Standard Errors<a href="concepts.html#clustering-standard-errors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>In the real world, though, you can never assume that errors are independent draws from the same distribution. You need to know how your variables were constructed in the first place in order to choose the correct error structure for calculating your standard errors. If you have aggregate variables, like class size, then you’ll need to cluster at that level. If some treatment occurred at the state level, then you’ll need to cluster at that level.</p></li>
<li><p>When the units of analysis are clustered into groups and the researcher suspects that the errors are correlated within (but not across) groups, it may be appropriate to employ variance estimators that are robust to the clustered nature of the data.</p></li>
<li><p>When we cluster standard errors at the state level, we allow for arbitrary serial correlation within state.</p></li>
<li><p>multi way clustering</p></li>
</ul>
<div id="when-should-you-adjust-standard-errors-for-clustering" class="section level4 hasAnchor" number="1.7.3.1">
<h4><span class="header-section-number">1.7.3.1</span> When Should You Adjust Standard Errors for Clustering?<a href="concepts.html#when-should-you-adjust-standard-errors-for-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Abadie et al 2022</li>
</ul>
<p>Formally, clustered standard errors adjust for the correlations induced by sampling the outcome variable from a data-generating process with unobserved cluster- level components.</p>
<p><a href="https://blogs.worldbank.org/en/impactevaluations/when-should-you-cluster-standard-errors-new-wisdom-econometrics-oracle">Source</a></p>
<p>The authors argue that there are two reasons for clustering standard errors:</p>
<p>1- a sampling design reason, which arises because you have sampled data from a population using clustered sampling, and want to say something about the broader population;</p>
<p>2- and an experimental design reason, where the assignment mechanism for some causal treatment of interest is clustered. Let me go through each in turn, by way of examples, and end with some of their takeaways.</p>
<p><strong>A Sampling Design reason</strong></p>
<p>Consider running a simple Mincer earnings regression of the form:
Log(wages) = a + b<em>years of schooling + c</em>experience + d*experience^2 + e</p>
<p>You present this model, and are deciding whether to cluster the standard errors. Referee 1 tells you “the wage residual is likely to be correlated within local labor markets, so you should cluster your standard errors by state or village.”. But referee 2 argues “The wage residual is likely to be correlated for people working in the same industry, so you should cluster your standard errors by industry”, and referee 3 argues that “the wage residual is likely to be correlated by age cohort, so you should cluster your standard errors by cohort”. What should you do?</p>
<p>Under the sampling perspective, what matters for clustering is how the sample was selected and whether there are clusters in the population of interest that are not represented in the sample. So, we can imagine different scenarios here:</p>
<ol style="list-style-type: decimal">
<li><p>You want to say something about the association between schooling and wages in a particular population, and are using a random sample of workers from this population. Then there is no need to adjust the standard errors for clustering at all, even if clustering would change the standard errors.</p></li>
<li><p>The sample was selected by randomly sampling 100 towns and villages from within the country, and then randomly sampling people in each; and your goal is to say something about the return to education in the overall population. Here you should cluster standard errors by village, since there are villages in the population of interest beyond those seen in the sample.</p></li>
<li><p>This same logic makes it clear why you generally wouldn’t cluster by age cohort (it seems unlikely that we would randomly sample some age cohorts and not others, and then try and say something about all ages);</p></li>
<li><p>and that we would only want to cluster by industry if the sample was drawn by randomly selecting a sample of industries, and then sampling individuals from within each.</p></li>
</ol>
<p>Even in the second case, Abadie et al. note that both the usual robust (Eicker-Huber-White or EHW) standard errors, and the clustered standard errors (which they call Liang-Zeger or LZ standard errors) can both be correct, it is just that they are correct for different estimands. That is, if you are content on just saying something about the particular sample of individuals you have, without trying to generalize to the population, the EHW standard errors are all you need; but if you want to say something about the broader population, the LZ standard errors are necessary.</p>
<p><strong>The Experimental Design Reason for Clustering</strong></p>
<p>The second reason for clustering is the one we are probably more familiar with, which is when clusters of units, rather than individual units, are assigned to a treatment. Let’s take the same equation as above, but assume that we have a binary treatment that assigns more schooling to people. So now we have:
Log(wages) = a +b*Treatment + e</p>
<p>Then if the treatment is assigned at the individual level, there is no need to cluster (*).</p>
<p>There has been much confusion about this, as Chris Blattman explored in two earlier posts about this issue (the fabulously titled clusterjerk and clusterjerk the sequel), and I still occasionally get referees suggesting I try clustering by industry or something similar in an individually-randomized experiment. This Abadie et al. paper is now finally a good reference to explain why this is not necessary.</p>
<p>(*) unless you are using multiple time periods, and then you will want to cluster by individual, since the unit of randomization is individual, and not individual-time period.</p>
<p>What about if your treatment is assigned at the village level. Then cluster by village. This is also why you want to cluster difference-in-differences at the state-level when you have a source of variation that comes from differences across states, and why a “treatment” like being on one side of a border vs the other is problematic (because you have only 2 clusters).</p>
</div>
</div>
</div>
<div id="types-of-biases-in-econometrics-statistics" class="section level2 hasAnchor" number="1.8">
<h2><span class="header-section-number">1.8</span> Types of Biases in Econometrics &amp; Statistics<a href="concepts.html#types-of-biases-in-econometrics-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Bias occurs when estimates systematically deviate from the truth, threatening validity and reliability. Below are the main types, grouped by theme.</p>
<div id="sample-selection-biases" class="section level3 hasAnchor" number="1.8.1">
<h3><span class="header-section-number">1.8.1</span> Sample &amp; Selection Biases<a href="concepts.html#sample-selection-biases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Selection Bias</strong>: Sample is not representative because inclusion depends on outcome or treatment.
<em>Example</em>: Studying education and earnings using only employed individuals.</li>
<li><strong>Self-Selection Bias</strong>: Individuals choose into groups in non-random ways.
<em>Example</em>: Motivated people opt into job training, biasing program effects.</li>
<li><strong>Attrition Bias</strong>: Dropouts differ systematically from those who remain.
<em>Example</em>: Only successful dieters remain in a long-term study.</li>
<li><strong>Survivorship Bias</strong>: Only “survivors” are analyzed, failures ignored.
<em>Example</em>: Measuring mutual fund returns using only funds still operating.</li>
</ul>
</div>
<div id="specification-confounding-biases" class="section level3 hasAnchor" number="1.8.2">
<h3><span class="header-section-number">1.8.2</span> Specification &amp; Confounding Biases<a href="concepts.html#specification-confounding-biases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Omitted Variable Bias</strong>: Leaving out a confounder that affects both X and Y.
<em>Example</em>: Estimating education’s effect on wages without controlling for ability.</li>
<li><strong>Confounding Bias</strong>: When the effect of X on Y is mixed with another variable’s effect.
<em>Example</em>: Estimating smoking → lung cancer without controlling for age.</li>
<li><strong>Endogeneity Bias</strong>: More general case where X is correlated with error term (due to omitted variables, measurement error, or simultaneity).</li>
</ul>
</div>
<div id="measurement-response-biases" class="section level3 hasAnchor" number="1.8.3">
<h3><span class="header-section-number">1.8.3</span> Measurement &amp; Response Biases<a href="concepts.html#measurement-response-biases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Measurement Bias</strong>: Variables measured incorrectly.
<em>Systematic</em>: A scale always adds 2 lbs.
<em>Random</em>: Data entry mistakes.</li>
<li><strong>Recall Bias</strong>: Inaccurate memory of past events.
<em>Example</em>: Patients misreport past diet.</li>
<li><strong>Response Bias</strong>: Participants misreport due to social desirability or misunderstanding.
<em>Example</em>: Underreporting alcohol use in surveys.</li>
<li><strong>Observer Bias</strong>: Researcher expectations influence outcomes.
<em>Example</em>: Therapist influences responses when testing a therapy.</li>
</ul>
</div>
<div id="analytical-reporting-biases" class="section level3 hasAnchor" number="1.8.4">
<h3><span class="header-section-number">1.8.4</span> Analytical &amp; Reporting Biases<a href="concepts.html#analytical-reporting-biases" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Publication Bias</strong>: Positive results more likely to be published.
<em>Example</em>: Meta-analysis overstates effects because null results stay unpublished.</p></li>
<li><p><strong>Overfitting Bias</strong>: Model fits noise in training data, fails to generalize.
<em>Example</em>: Complex regression with too many parameters.</p></li>
<li><p><strong>Confirmation Bias</strong>: Selectively seeking or interpreting evidence consistent with prior beliefs.</p></li>
</ul>
</div>
<div id="addressing-bias" class="section level3 hasAnchor" number="1.8.5">
<h3><span class="header-section-number">1.8.5</span> Addressing Bias<a href="concepts.html#addressing-bias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><strong>Randomization</strong> → Prevents selection &amp; confounding bias.</li>
<li><strong>Control Groups</strong> → Benchmark against counterfactual.</li>
<li><strong>Instrumental Variables (IV)</strong> → Correct for endogeneity.</li>
<li><strong>Panel Methods / DiD</strong> → Handle unobserved heterogeneity.</li>
<li><strong>Propensity Score Matching (PSM)</strong> → Balance observed covariates in non-experimental data.</li>
<li><strong>Heckman Selection Models</strong> → Correct for self-selection.</li>
<li><strong>Blinding &amp; Survey Design</strong> → Reduce response and observer bias.</li>
<li><strong>Robustness Checks &amp; Sensitivity Analyses</strong> → Test stability of results.</li>
</ul>
</div>
</div>
<div id="causality" class="section level2 hasAnchor" number="1.9">
<h2><span class="header-section-number">1.9</span> Causality<a href="concepts.html#causality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s summarize the main definitions and perspectives so you can see them side by side:</p>
<div id="counterfactual-potential-outcomes-definition" class="section level3 hasAnchor" number="1.9.1">
<h3><span class="header-section-number">1.9.1</span> Counterfactual (Potential Outcomes) Definition<a href="concepts.html#counterfactual-potential-outcomes-definition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Core idea</strong>: A cause is something that changes the outcome relative to what would have happened otherwise.</p></li>
<li><p><strong>Formalized by</strong>: Rubin Causal Model (Neyman–Rubin framework).</p></li>
<li><p><strong>Definition</strong>: Treatment <span class="math inline">\(T\)</span> causes outcome <span class="math inline">\(Y\)</span> if <span class="math inline">\(Y(1) \neq Y(0)\)</span>, where <span class="math inline">\(Y(1)\)</span> is the potential outcome if treated, and <span class="math inline">\(Y(0)\)</span> is the potential outcome if untreated.</p></li>
<li><p><strong>Key Challenge</strong>: We never observe both <span class="math inline">\(Y(1)\)</span> and <span class="math inline">\(Y(0)\)</span> for the same individual → leads to the <strong>fundamental problem of causal inference</strong>.</p></li>
</ul>
</div>
<div id="causal-graphs-structural-causal-models-dags" class="section level3 hasAnchor" number="1.9.2">
<h3><span class="header-section-number">1.9.2</span> Causal Graphs (Structural Causal Models / DAGs)<a href="concepts.html#causal-graphs-structural-causal-models-dags" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Core idea</strong>: Causes are encoded in the structure of a system of equations or directed acyclic graphs (DAGs).</p></li>
<li><p><strong>Formalized by</strong>: Judea Pearl (Structural Causal Models).</p></li>
<li><p><strong>Definition</strong>: A variable <span class="math inline">\(X\)</span> is a cause of <span class="math inline">\(Y\)</span> if intervening on <span class="math inline">\(X\)</span> (via the “do” operator, <span class="math inline">\(\text{do}(X=x)\)</span>) changes the distribution of <span class="math inline">\(Y\)</span>.</p></li>
<li><p><strong>Key Tool</strong>: Backdoor criterion, front-door criterion, do-calculus.</p></li>
</ul>
</div>
<div id="experimental-interventionist-definition" class="section level3 hasAnchor" number="1.9.3">
<h3><span class="header-section-number">1.9.3</span> Experimental (Interventionist) Definition<a href="concepts.html#experimental-interventionist-definition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Core idea</strong>: A cause is something that can be manipulated and produces a systematic change in the outcome.</p></li>
<li><p><strong>Philosophical basis</strong>: Interventionist theories (e.g., Woodward).</p></li>
<li><p><strong>Definition</strong>: <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> if manipulating <span class="math inline">\(X\)</span> while holding everything else constant changes <span class="math inline">\(Y\)</span>.</p></li>
<li><p><strong>Key Application</strong>: Randomized controlled trials (RCTs) embody this definition.</p></li>
</ul>
</div>
<div id="econometric-definition" class="section level3 hasAnchor" number="1.9.4">
<h3><span class="header-section-number">1.9.4</span> Econometric Definition<a href="concepts.html#econometric-definition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Core idea</strong>: Causes are identified when changes in a regressor can be isolated as exogenous and not confounded.</p></li>
<li><p><strong>Formalized by</strong>: Econometrics tradition (Haavelmo, Angrist &amp; Pischke).</p></li>
<li><p><strong>Definition</strong>: <span class="math inline">\(X\)</span> causes <span class="math inline">\(Y\)</span> if variation in <span class="math inline">\(X\)</span> that is independent of confounders systematically shifts <span class="math inline">\(Y\)</span>.</p></li>
<li><p><strong>Key Tools</strong>: IV, DiD, panel fixed effects, RCTs, natural experiments.</p></li>
</ul>
</div>
<div id="philosophical-humean-regularity-definition" class="section level3 hasAnchor" number="1.9.5">
<h3><span class="header-section-number">1.9.5</span> Philosophical (Humean / Regularity) Definition<a href="concepts.html#philosophical-humean-regularity-definition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Core idea</strong>: A cause is something that is regularly followed by an effect.</p></li>
<li><p><strong>David Hume’s view</strong>: “We may define a cause to be an object, followed by another, and where all the objects similar to the first are followed by objects similar to the second.”</p></li>
<li><p><strong>Limitations</strong>: Regularity doesn’t distinguish correlation from causation.</p></li>
</ul>
</div>
<div id="granger-causality-time-series" class="section level3 hasAnchor" number="1.9.6">
<h3><span class="header-section-number">1.9.6</span> Granger Causality (Time Series)<a href="concepts.html#granger-causality-time-series" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><strong>Core idea</strong>: In time series, <span class="math inline">\(X\)</span> Granger-causes <span class="math inline">\(Y\)</span> if past values of <span class="math inline">\(X\)</span> improve predictions of <span class="math inline">\(Y\)</span> beyond past values of <span class="math inline">\(Y\)</span> alone.</p></li>
<li><p><strong>Definition</strong>: <span class="math inline">\(X\)</span> Granger-causes <span class="math inline">\(Y\)</span> if <span class="math inline">\(P(Y\_t | Y\_{t-1}, X\_{t-1}) \neq P(Y\_t | Y\_{t-1})\)</span>.</p></li>
<li><p><strong>Limitation</strong>: Not true causality—predictive, not structural.</p></li>
</ul>
</div>
<div id="summary-table" class="section level3 hasAnchor" number="1.9.7">
<h3><span class="header-section-number">1.9.7</span> Summary Table<a href="concepts.html#summary-table" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="15%" />
<col width="31%" />
<col width="22%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Definition</strong></th>
<th><strong>Key Idea</strong></th>
<th><strong>Main Advocates</strong></th>
<th><strong>Limitations</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Counterfactual</td>
<td>Compare <span class="math inline">\(Y(1)\)</span> vs. <span class="math inline">\(Y(0)\)</span></td>
<td>Rubin, Neyman</td>
<td>Missing data problem</td>
</tr>
<tr class="even">
<td>Causal Graphs (SCM)</td>
<td>Intervention via “do” operator</td>
<td>Pearl</td>
<td>Requires structural assumptions</td>
</tr>
<tr class="odd">
<td>Experimental</td>
<td>Manipulation changes outcomes</td>
<td>Woodward, RCT tradition</td>
<td>Not always feasible</td>
</tr>
<tr class="even">
<td>Econometric</td>
<td>Exogenous variation identifies effects</td>
<td>Haavelmo, Angrist &amp; Pischke</td>
<td>Depends on valid instruments/design</td>
</tr>
<tr class="odd">
<td>Philosophical</td>
<td>Constant conjunction / regularity</td>
<td>Hume</td>
<td>Doesn’t separate correlation</td>
</tr>
<tr class="even">
<td>Granger Causality</td>
<td>Predictive precedence in time</td>
<td>Clive Granger</td>
<td>Predictive, not structural</td>
</tr>
</tbody>
</table>
<hr />
<p>👉 <strong>Bottom line</strong>:</p>
<ul>
<li>In <strong>econometrics</strong>, we mostly rely on <strong>counterfactuals</strong> + <strong>exogenous variation (econometric definition)</strong>.</li>
<li>In <strong>statistics</strong>, the <strong>Rubin model</strong> dominates.</li>
<li>In <strong>computer science/AI</strong>, Pearl’s <strong>SCM/DAGs</strong> dominate.</li>
<li>In <strong>time series</strong>, <strong>Granger causality</strong> is used, but cautiously.</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="potential-outcomes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Causal Methods.pdf", "Causal Methods.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
