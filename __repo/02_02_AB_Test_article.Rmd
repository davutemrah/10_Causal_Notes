## Example: A/B Test


A/B testing is an experiment where two or more variants are evaluated using statistical analysis to determine which variation performs better for a given conversion goal.

A/B testing is widely used by digital marketing agencies as it is the most effective method to determine the best content for converting visits into sign-ups and purchases.

In this scenario, you will set up hypothesis testing to advise a digital marketing agency on whether to adopt a new ad they designed for their client.

Assume you are hired by a digital marketing agency to conduct an A/B test on a new ad hosted on a website. Your task is to determine whether the new ad outperforms the existing one.

The agency has run an experiment where one group of users was shown the new ad design, while another group was shown the old ad design. The users' interactions with the ads were observed, specifically whether they clicked on the ad or not.


### Task 1: Load the data

In this task, we will import our libraries and then load our
dataset

```{r, warning=FALSE}
library(tidyverse)
library(readxl)
df <- read_excel('/Users/deayan/Desktop/GITHUB/10_Causal_Notes/__repo/data/AB_Test.xlsx')
```



```{r}
glimpse(df)
```

```{r}
df%>%
  group_by(group, action)%>%
  summarise(n = n(),
            .groups = "drop")
```


### Task 2: Set up Hypothesis

**experiment group**: the group that is involved in the new experiment . i.e the group that received the new ad .

**Control group**:
the 2nd group that didn't receive the new ad

**Click-through rate (CTR)**:
the number of clicks advertisers receive on their ads per number of impressions.

```{r}
table(df$group)
```

```{r}
df%>%count(group)
```


```{r}
table(df)
```

```{r}
prop.table(table(df), 1)
```

```{r}
df %>%
  count(group) %>%
  mutate(prop = n / sum(n))
```

```{r}
x <- df %>%
  group_by(group, action)%>%
  summarise(n = n(), .groups = 'drop')%>%
  pivot_wider(names_from = action, values_from = n, values_fill = list(n = 0))
  
names(x) <- c("group", "view", "view_click")

x%>%
  group_by(group)%>%
  transmute(view1 = view/(view+view_click),
         view_click1 = view_click/(view+view_click))
``` 


The **null hypothesis** is what we assume to be true before we collect the data, and the **alternative hypothesis** is usually what we want to try and prove to be true.

So in our experiment than null hypothesis is assuming that the old ad is better than than new one. 

Then we set the **significance level** $\alpha$. 

The **significance level** is the probability of rejecting the null hypothesis when it's true. (Type I error rate)

For example, a significance level of 0.05 indicates a 5% risk of concluding that a difference exists when there is no actual difference.

**Lower significance** levels indicate that you require stronger
evidence before you reject the null hypothesis.

So we will set our significance level to be 0.05. And if we reject the null hypothesis as a result of our experiment, then by having significant level of 0.05 then we are 95% confident that we can reject the null hypothesis.

So setting the significance level is about how confident you are while you reject the null hypothesis, the fourth step is calculating the corresponding P value.

The definition of **P value** is the probability of observing your statistic, if the null hypothesis is true. And then we will draw a conclusion whether to go for the new ad or not.

**Hypothesis Testing steps:**
1) Specify the Null Hypothesis.   
2) Specify the Alternative Hypothesis.   
3) Set the Significance Level (a)   
4) Calculate the Corresponding P-Value.   
5) Drawing a Conclusion  


**Our Hypothesis**

Hypothesis is that the click through rate associated with the new ad is less than that associated with the old ad, which means that the old ad is better than than new one.

And the alternative hypothesis will be the opposite.


### Task 3: Compute the difference in the click-through rate 

This task we will compute the difference in the click through rate between the control and experiment groups.

```{r}
control_df <- df[df$group == "control", ]
experiment_df <- df[df$group == "experiment", ]
```

```{r}
control_ctr <- 
    mean(ifelse(control_df$action=="view and click", 1, 0))

experiment_ctr <-
    mean(ifelse(experiment_df$action=="view and click", 1, 0))

diff <- experiment_ctr - control_ctr
diff
```

### Task four : create sample distribution using bootsrapping

#### Bootstrapping : 

The bootstrap method is a statistical technique for estimating quantities about a population by averaging estimates from multiple small data samples.

Importantly, samples are constructed by drawing observations from a large data sample one at a time and returning them to the data sample after they have been chosen. This allows a given observation to be included in a given small sample more than once. This approach to sampling is called sampling with replacement.

#### Example : 

Bootstrapping in statistics, means sampling with replacement.
So, if we have a group of individuals and , and want to bootstrap sample of ten individuals from this group , we could randomly sample any ten individuals but with bootsrapping, we are sampling with replacement so we could actually end up sampling 7 out of the ten individuals and three of the previously selected individuals might end up being sampled again.


```{r}
set.seed(1234)
difference <- numeric()
size <- dim(df)[1]

for (i in 1:10000){
    sample_index <- sample(1:nrow(df), size = size, replace = TRUE)
    sample_df <- df[sample_index, ]
    controls_df <- sample_df[sample_df$group=="control",]
    experiments_df <- sample_df[sample_df$group=="experiment",]
    
    controls_ctr <- mean(ifelse(controls_df$action=="view and click", 1, 0))
    experiments_ctr <- mean(ifelse(experiments_df$action=="view and click", 1, 0))
    
    difference <- append(difference, experiments_ctr - controls_ctr)
}

```

### Task five : Evaluate the null hypothesis and draw conclustions.

 The central limit theorem states that if you have a population with mean μ and standard deviation σ and take sufficiently large random samples from the population with replacement , then the distribution of the sample means will be approximately normally distributed.
 
 
```{r}
hist(difference)
```
 
simulate the distribution under the null hypothesis (difference = 0)

```{r}
null_hypothesis <- rnorm(n = length(difference), mean=0, sd=sd(difference))

hist(null_hypothesis)
abline(v= diff, col = "red")
```
 
The definition of a **p-value** is the probability of observing your statistic (or one more extreme in favor of the alternative) if the null hypothesis is true.
 
The confidence level is equivalent to 1 – the alpha level. So, if your significance level is 0.05, the corresponding confidence level is 95%.

i.e for P Value less than 0.05 we are 95% percent confident that we can reject the null hypothesis

**compute p-value**

```{r}
mean((null_hypothesis > diff))
```

It says that we dont reject the null hypothesis. We can find more extreme values than our test statistics 98% of the time if the null hypothesis true.
 

 
 
 
 
 
 
 
 
 
 
 
